{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI security system.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hLaDlW3Jh6p1"},"source":["# Welcome to AI security assistance system\n","\n","Have you ever considered the job of a security officer. In some schools, office buildings and even appartements, there is often one individual who is tasked with observing feeds from multiple security cameras. These security guards are capable of making mistakes. Now let us consider the situation of a theft or burglary. It is important for the security officials to be able to easily notified when there is a person on a video feed. That is what we will be solving today. We will be creating a system that is able to detect if there is a person detected on a video feed and alerting the user about it. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"K2H86v5Gh6p3"},"source":["In order to detect the people from the  camera we will be using the 'person-detection-retail-0013' pre-trained models from the OpenVINO model zoo. You can find out more about it here ->https://docs.openvinotoolkit.org/2019_R1/usergroup1.html\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"XllAH74rh6p6","colab":{}},"source":["import cv2 #importing all required libraries\n","import numpy as np\n","from utils.opv import OpvModel  \n","import matplotlib.pyplot as plt\n","import winsound"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ihSS7Wwzh6qE"},"source":["## Task: Load the pretrained model "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ScLZlh48h6qG","colab":{}},"source":["mymodel2 = OpvModel(\"#enter the name of the pretrained model here\",device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n","#depending on whether you are using Neural Compute Stick you can set the value of ncs to 0 or 1, if not using NCS change device from Myriad to CPU"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Ex-3A0C1h6qP","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"INezb-3ah6qu"},"source":["## Task: Draw Bounding Box around the person\n","\n","We create a function to draw a bounding box around the person that has been detected.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ilhZ-W_Nh6qx","colab":{}},"source":["def DrawBoundingBoxes(predictions, image): # the input will come from the main code\n","    canvas = image.copy()                             # copy instead of modifying the original image\n","    conf = 0\n","    predictions = predictions[0][0]\n","    confidence = predictions[:,2]\n","    topresults = predictions[(confidence>conf)]\n","    (h,w) = canvas.shape[:2]\n","    for detection in topresults:\n","        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n","        (xmin, ymin, xmax, ymax) = box.astype(\"int\")# assign box location value to xmin, ymin, xmax, ymax\n","\n","        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n","        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n","            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n","    cv2.putText(canvas, str(len(topresults))+\" persons(s) detected\", (50,50),# include text\n","            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n","    return canvas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WnkfT_xSh6q7","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IDZcMfV_h6rD","colab":{}},"source":["## Task: The main code\n","\n","Here is the main code. It turns on our webcam, capture an image upon user request, process that image by calling other user-defined functions, and compare the resulting vector into our vector database. \n","\n","This code should be activated the last, after running the tabs below it. \n","\n","For this part of the code we will be using a live video feed."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CY3WaW3Cdeg","colab_type":"code","colab":{}},"source":["camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n","\n","\n","\n","while(True):\n","               # write code to Capture frame by frame      \n","    \n","    \n","    cv2.imshow('Press Spacebar to Exit',DrawBoundingBoxes(predictions,frame))\n","    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n","        break\n","\n","camera.release()                           # Cleanup after spacebar is detected.\n","cv2.destroyAllWindows()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ztpt0O89Cdej","colab_type":"text"},"source":["Seems that we are drawing far too many boxes. However, not every bounding box may be a face. To see which are valid predictions, we will need to compare the probability scores against a threshold that we set."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2ZNZoZKNh6rL"},"source":["## Task: Create a threshold.\n","\n","If there is a person detected on the screen then alert the user through a \"beep\" sound."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"mKugl4mbh6rN","colab":{}},"source":["def DrawBoundingBoxes(predictions, image, conf =#Set appropriate confidence interval here):\n","    canvas = image.copy()                             # copy instead of modifying the original image\n","    predictions = predictions[0][0]\n","    confidence = predictions[:,2]\n","    topresults = predictions[(confidence>conf)]\n","    (h,w) = canvas.shape[:2]\n","    for detection in topresults:\n","        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n","        (xmin, ymin, xmax, ymax) = box.astype(\"int\")# assign box location value to xmin, ymin, xmax, ymax\n","\n","        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4) # make a rectangle\n","        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n","            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n","    cv2.putText(canvas, str(len(topresults))+\" persons(s) detected\", (50,50),# include text\n","            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n","    if len(topresults) > 0:\n","        winsound.Beep(3000,20)\n","    \n","    return canvas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"viuh03zph6rT","colab":{}},"source":["Let's try again with the modified Confidence interval!"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J_8WmVJQh6rb","colab":{}},"source":["camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n","\n","\n","\n","while(True):\n","               # write code to Capture frame by frame      \n","    \n","    \n","    cv2.imshow('Press Spacebar to Exit',DrawBoundingBoxes(predictions,frame))\n","    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n","        break\n","\n","camera.release()                           # Cleanup after spacebar is detected.\n","cv2.destroyAllWindows()\n"],"execution_count":null,"outputs":[]}]}