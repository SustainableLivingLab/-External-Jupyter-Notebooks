{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial landmark vector mapping\n",
    "\n",
    "Here, we will be saving vector map into a pickle file for the target faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils.opv import OpvModel\n",
    "\n",
    "#mymodel0 = OpvModel(\"face-detection-adas-0001\", device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n",
    "mymodel0 = OpvModel(\"face-detection-adas-0001\", device=\"GPU\", fp=\"FP32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = cv2.imread(\"images/Arvin/Arvin_1.jpg\")\n",
    "#friends = cv2.resize(friends,(1200,710))     #Downsize the image since the original is quite large\n",
    "predictions = mymodel0.Predict(friends)\n",
    "\n",
    "cv2.imshow(\"Friends2\",friends)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=.6):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # \n",
    "    for detection in topresults:\n",
    "        \n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    \n",
    "    #global face_box\n",
    "    face_box = image[ymin:ymax,ymin:ymax]\n",
    "    \n",
    "    cv2.imshow(\"canvas\",canvas)\n",
    "    cv2.imshow(\"face_box\",face_box)\n",
    "    #cv2.waitKey(5000)\n",
    "    cv2.imwrite( \"images/Arvin/Avbox_1.jpeg\", face_box )           \n",
    "    #Show result image for 0,5 sec on screen\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return \n",
    "\n",
    "#cv2.imshow(\"Friends2\",DrawBoundingBoxes(predictions,friends))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [],
   "source": [
    "DrawBoundingBoxes(predictions,friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 94, 108, 131],\n",
       "        [ 95, 109, 132],\n",
       "        [ 96, 110, 132],\n",
       "        ...,\n",
       "        [136, 156, 144],\n",
       "        [136, 156, 144],\n",
       "        [136, 156, 144]],\n",
       "\n",
       "       [[ 94, 108, 131],\n",
       "        [ 95, 109, 132],\n",
       "        [ 96, 110, 132],\n",
       "        ...,\n",
       "        [136, 156, 144],\n",
       "        [136, 156, 144],\n",
       "        [135, 155, 143]],\n",
       "\n",
       "       [[ 94, 108, 131],\n",
       "        [ 95, 109, 132],\n",
       "        [ 96, 110, 132],\n",
       "        ...,\n",
       "        [136, 156, 144],\n",
       "        [135, 155, 143],\n",
       "        [135, 155, 143]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[129, 128, 137],\n",
       "        [127, 126, 135],\n",
       "        [125, 125, 131],\n",
       "        ...,\n",
       "        [175, 254, 221],\n",
       "        [175, 254, 221],\n",
       "        [175, 254, 221]],\n",
       "\n",
       "       [[126, 125, 134],\n",
       "        [125, 124, 133],\n",
       "        [124, 124, 130],\n",
       "        ...,\n",
       "        [175, 254, 221],\n",
       "        [175, 254, 221],\n",
       "        [175, 254, 221]],\n",
       "\n",
       "       [[123, 122, 131],\n",
       "        [123, 122, 131],\n",
       "        [123, 123, 129],\n",
       "        ...,\n",
       "        [175, 254, 221],\n",
       "        [175, 254, 221],\n",
       "        [175, 254, 221]]], dtype=uint8)"
      ]
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_box"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landmark Regression from [here](https://docs.openvinotoolkit.org/2018_R5/_docs_Retail_object_attributes_landmarks_regression_0009_onnx_desc_landmarks_regression_retail_0009.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mymodel = OpvModel(\"face-reidentification-retail-0095\", device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n",
    "mymodel1 = OpvModel(\"landmarks-regression-retail-0009\", device=\"GPU\", fp=\"FP32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#src = cv2.imread(\"./images/Arihant/Abox_7.jpeg\")\n",
    "#src = cv2.imread(\"./images/girl.jpg\")\n",
    "src = cv2.imread(\"images/denied.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 40 # percent of original size\n",
    "#scale_percent = 20 # percent of original size\n",
    "width = int(src.shape[1] * scale_percent / 100)\n",
    "height = int(src.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "src = cv2.resize(src, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(501, 752, 3)"
      ]
     },
     "execution_count": 1170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Input\", src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM = src.shape[0]\n",
    "\n",
    "img = np.zeros((height, width, 3), dtype = \"uint8\") \n",
    "\n",
    "# Creating a polyline with the 5 points depicting left eye, right eye, tip of nose, left lip corner, right lip corner\n",
    "points = np.array([[[0.31556875000000000 * DIM, 0.4615741071428571* DIM], [0.68262291666666670 * DIM, 0.4615741071428571 * DIM], [0.50026249999999990 * DIM, 0.6405053571428571 * DIM], [0.34947187500000004 * DIM, 0.8246919642857142 * DIM], [0.65343645833333330 * DIM, 0.8246919642857142* DIM]]], np.int32)\n",
    "cv2.polylines(img, [points], True, (255, 255, 255), thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite( \"images/denied.jpeg\", src )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 414, 3)\n",
      "(414, 414, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(src))\n",
    "print(np.shape(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mymodel1.Predict(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (type(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.20495585]]\n",
      "\n",
      "  [[0.3791675 ]]\n",
      "\n",
      "  [[0.54892147]]\n",
      "\n",
      "  [[0.36624804]]\n",
      "\n",
      "  [[0.3585889 ]]\n",
      "\n",
      "  [[0.549249  ]]\n",
      "\n",
      "  [[0.24255645]]\n",
      "\n",
      "  [[0.75736094]]\n",
      "\n",
      "  [[0.52947026]]\n",
      "\n",
      "  [[0.7552715 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_eye = tuple([int(DIM*i) for i in (predictions[0,0,0,0], predictions[0,1,0,0])])   \n",
    "r_eye = tuple([int(DIM*i) for i in (predictions[0,2,0,0], predictions[0,3,0,0])]) \n",
    "nose = tuple([int(DIM*i) for i in (predictions[0,4,0,0], predictions[0,5,0,0])]) \n",
    "l_lip = tuple([int(DIM*i) for i in (predictions[0,6,0,0], predictions[0,7,0,0])]) \n",
    "r_lip = tuple([int(DIM*i) for i in (predictions[0,8,0,0], predictions[0,9,0,0])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(l_eye)\n",
    "#print(r_eye)\n",
    "#print(nose)\n",
    "#print(l_lip)\n",
    "#print(r_lip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[114, 125, 129],\n",
       "        [109, 120, 124],\n",
       "        [ 96, 105, 109],\n",
       "        ...,\n",
       "        [166, 178, 178],\n",
       "        [166, 178, 180],\n",
       "        [166, 178, 180]],\n",
       "\n",
       "       [[122, 133, 137],\n",
       "        [108, 117, 121],\n",
       "        [ 96, 102, 107],\n",
       "        ...,\n",
       "        [166, 178, 178],\n",
       "        [166, 178, 180],\n",
       "        [166, 178, 180]],\n",
       "\n",
       "       [[ 95, 104, 108],\n",
       "        [ 90,  99, 103],\n",
       "        [ 89,  94,  99],\n",
       "        ...,\n",
       "        [166, 178, 178],\n",
       "        [166, 178, 180],\n",
       "        [166, 178, 180]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[182, 147, 114],\n",
       "        [166, 132,  99],\n",
       "        [156, 123,  93],\n",
       "        ...,\n",
       "        [187, 195, 185],\n",
       "        [188, 196, 186],\n",
       "        [188, 196, 186]],\n",
       "\n",
       "       [[171, 133, 101],\n",
       "        [158, 123,  93],\n",
       "        [151, 119,  90],\n",
       "        ...,\n",
       "        [187, 195, 185],\n",
       "        [187, 195, 185],\n",
       "        [187, 195, 185]],\n",
       "\n",
       "       [[163, 126,  96],\n",
       "        [157, 122,  94],\n",
       "        [156, 124,  99],\n",
       "        ...,\n",
       "        [187, 195, 185],\n",
       "        [187, 195, 185],\n",
       "        [187, 195, 185]]], dtype=uint8)"
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.circle(src,l_eye, 1, (0,0,255), -1)\n",
    "cv2.circle(src,r_eye, 1, (0,0,255), -1)\n",
    "cv2.circle(src,nose, 1, (0,0,255), -1)\n",
    "cv2.circle(src,l_lip, 1, (0,0,255), -1)\n",
    "cv2.circle(src,r_lip, 1, (0,0,255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_percent = 100 # percent of original size\n",
    "#scale_percent = 20 # percent of original size\n",
    "width = int(src.shape[1] * scale_percent / 100)\n",
    "height = int(src.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "src = cv2.resize(src, dim, interpolation = cv2.INTER_AREA)\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Input\", src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = src\n",
    "\n",
    "rows,cols,ch = src.shape\n",
    "\n",
    "pts1 = np.float32([l_eye,r_eye,l_lip,r_lip])\n",
    "pts2 = np.float32([[DIM*0.31556875000000000, DIM*0.4615741071428571],\\\n",
    "                   [DIM*0.68262291666666670, DIM*0.4615741071428571],\\\n",
    "                   [DIM*0.34947187500000004, DIM*0.8246919642857142],\\\n",
    "                   [DIM*0.65343645833333330, DIM*0.8246919642857142]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "dst = cv2.warpPerspective(src,M, (width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(414, 414, 3)\n",
      "(414, 414, 3)\n"
     ]
    }
   ],
   "source": [
    "background = img\n",
    "overlay = dst\n",
    "print(np.shape(background))\n",
    "print(np.shape(overlay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "added_image = cv2.addWeighted(background,0.1,overlay,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Source image', src)\n",
    "cv2.imshow('Warp', dst)\n",
    "#cv2.imshow('dark', img) \n",
    "#cv2.imshow('Warp + Overlay', added_image)\n",
    "\n",
    "cv2.imwrite( \"images/Arvin/Avbox_1.jpeg\", dst )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reidentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils.opv import OpvModel\n",
    "\n",
    "mymodel2 = OpvModel(\"face-reidentification-retail-0095\", device=\"CPU\", fp=\"FP32\")\n",
    "#mymodel = OpvModel(\"face-reidentification-retail-0095\", device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n",
    "#mymodel2 = OpvModel(\"face-reidentification-retail-0095\", device=\"CPU\", fp=\"FP32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "metadata": {},
   "outputs": [],
   "source": [
    "aface1 = cv2.imread(\"./images/Arihant/Abox_4.jpeg\")\n",
    "aface2 = cv2.imread(\"./images/Arihant/Abox_6.jpeg\")\n",
    "aface3 = cv2.imread(\"./images/Arihant/Abox_8.jpeg\")\n",
    "dface1 = cv2.imread(\"./images/Daniel/Dbox_1.jpeg\")\n",
    "dface2 = cv2.imread(\"./images/Daniel/Dbox_2.jpeg\")\n",
    "dface3 = cv2.imread(\"./images/Daniel/Dbox_3.jpeg\")\n",
    "avface1 = cv2.imread(\"./images/Arvin/Avbox_1.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiona1 = mymodel2.Predict(aface1)\n",
    "predictiona2 = mymodel2.Predict(aface2)\n",
    "predictiona3 = mymodel2.Predict(aface3)\n",
    "\n",
    "predictiond1 = mymodel2.Predict(dface1)\n",
    "predictiond2 = mymodel2.Predict(dface2)\n",
    "predictiond3 = mymodel2.Predict(dface3)\n",
    "\n",
    "predictionav1 = mymodel2.Predict(avface1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiona1_flat = predictiona1.flatten()\n",
    "predictiona1_flat = predictiona1_flat.reshape(1, 256)\n",
    "\n",
    "predictiona2_flat = predictiona2.flatten()\n",
    "predictiona2_flat = predictiona2_flat.reshape(1, 256)\n",
    "\n",
    "predictiona3_flat = predictiona3.flatten()\n",
    "predictiona3_flat = predictiona3_flat.reshape(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictiond1_flat = predictiond1.flatten()\n",
    "predictiond1_flat = predictiond1_flat.reshape(1, 256)\n",
    "\n",
    "predictiond2_flat = predictiond2.flatten()\n",
    "predictiond2_flat = predictiond2_flat.reshape(1, 256)\n",
    "\n",
    "predictiond3_flat = predictiond3.flatten()\n",
    "predictiond3_flat = predictiond3_flat.reshape(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionav1_flat = predictionav1.flatten()\n",
    "predictionav1_flat = predictionav1_flat.reshape(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosim_a1_a1 = cosine_similarity(predictiona1_flat, predictiona1_flat)\n",
    "cosim_a1_a2 = cosine_similarity(predictiona1_flat, predictiona2_flat)\n",
    "cosim_a1_a3 = cosine_similarity(predictiona1_flat, predictiona3_flat)\n",
    "\n",
    "cosim_d1_d1 = cosine_similarity(predictiond1_flat, predictiond1_flat)\n",
    "cosim_d1_d2 = cosine_similarity(predictiond1_flat, predictiond2_flat)\n",
    "cosim_d1_d3 = cosine_similarity(predictiond1_flat, predictiond3_flat)\n",
    "\n",
    "cosim_a1_d1 = cosine_similarity(predictiona1_flat, predictiond1_flat)\n",
    "cosim_a1_d2 = cosine_similarity(predictiona1_flat, predictiond2_flat)\n",
    "cosim_a1_d3 = cosine_similarity(predictiona1_flat, predictiond3_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001]]\n",
      "[[0.9110678]]\n",
      "[[0.7673985]]\n",
      "[[1.]]\n",
      "[[0.8520222]]\n",
      "[[0.7521953]]\n",
      "[[-0.18649387]]\n",
      "[[-0.12147305]]\n",
      "[[-0.16873385]]\n"
     ]
    }
   ],
   "source": [
    "print(cosim_a1_a1)\n",
    "print(cosim_a1_a2)\n",
    "print(cosim_a1_a3)\n",
    "\n",
    "print(cosim_d1_d1)\n",
    "print(cosim_d1_d2)\n",
    "print(cosim_d1_d3)\n",
    "\n",
    "print(cosim_a1_d1)\n",
    "print(cosim_a1_d2)\n",
    "print(cosim_a1_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the  vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "with open('arihant.pickle', 'wb') as f:\n",
    "    pickle.dump(predictiona1_flat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('daniel.pickle', 'wb') as f:\n",
    "    pickle.dump(predictiond1_flat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('arvin.pickle', 'wb') as f:\n",
    "    pickle.dump(predictionav1_flat, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "def DrawBoundingBoxes(predictions, image, conf=0.5):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions = predictions[0][0]\n",
    "    confidence = predictions[:,2]\n",
    "    topresults = predictions[(confidence>conf)]\n",
    "    (h,w) = canvas.shape[:2]\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h])\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return canvas\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    predictions = mymodel.Predict(frame)\n",
    "    face_box\n",
    "    predictions1 = mymodel1.Predict(face_box)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit',DrawBoundingBoxes(predictions,frame))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
