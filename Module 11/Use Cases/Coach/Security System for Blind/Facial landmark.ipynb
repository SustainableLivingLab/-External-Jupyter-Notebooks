{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facial landmark vector mapping\n",
    "\n",
    "Here, we will be saving vector map into a pickle file for the target faces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:25:41.456514Z",
     "start_time": "2021-03-18T08:25:39.535197Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\001 SL2 Notes\\23feb downloaded files\\Github v3\\AI4YExpress\\Use Cases\\Coach\\Security System for Blind\\utils\\opv.py:86: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  self.input_layer = next(iter(net.inputs))\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils.opv import OpvModel\n",
    "\n",
    "#mymodel0 = OpvModel(\"face-detection-adas-0001\", device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n",
    "mymodel0 = OpvModel(\"face-detection-adas-0001\", device=\"GPU\", fp=\"FP32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:25:47.487243Z",
     "start_time": "2021-03-18T08:25:45.174116Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "friends = cv2.imread(\"resources/images/Arvin/Arvin_1.jpg\")\n",
    "#friends = cv2.resize(friends,(1200,710))     #Downsize the image since the original is quite large\n",
    "predictions = mymodel0.Predict(friends)\n",
    "\n",
    "cv2.imshow(\"Friends2\",friends)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:25:50.651975Z",
     "start_time": "2021-03-18T08:25:50.646946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:27:20.693168Z",
     "start_time": "2021-03-18T08:27:20.684169Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=.6):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # \n",
    "    for detection in topresults:\n",
    "        \n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    \n",
    "    #global face_box\n",
    "    face_box = image[ymin:ymax,ymin:ymax]\n",
    "    \n",
    "    cv2.imshow(\"canvas\",canvas)\n",
    "    cv2.imshow(\"face_box\",face_box)\n",
    "    #cv2.waitKey(5000)\n",
    "    cv2.imwrite( \"images/Arvin/Avbox_1.jpeg\", face_box )           \n",
    "    #Show result image for 0,5 sec on screen\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:27:24.894724Z",
     "start_time": "2021-03-18T08:27:22.885949Z"
    }
   },
   "outputs": [],
   "source": [
    "DrawBoundingBoxes(predictions,friends)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Landmark Regression from [here](https://docs.openvinotoolkit.org/2018_R5/_docs_Retail_object_attributes_landmarks_regression_0009_onnx_desc_landmarks_regression_retail_0009.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:27:35.498511Z",
     "start_time": "2021-03-18T08:27:35.325446Z"
    }
   },
   "outputs": [],
   "source": [
    "#mymodel = OpvModel(\"face-reidentification-retail-0095\", device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n",
    "# mymodel1 = OpvModel(\"landmarks-regression-retail-0009\", device=\"GPU\", fp=\"FP32\")\n",
    "mymodel1 = OpvModel(\"landmarks-regression-retail-0009\", device=\"CPU\", fp=\"FP32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:35:57.434066Z",
     "start_time": "2021-03-18T08:35:57.389057Z"
    }
   },
   "outputs": [],
   "source": [
    "#src = cv2.imread(\"./images/Arihant/Abox_7.jpeg\")\n",
    "#src = cv2.imread(\"./images/girl.jpg\")\n",
    "# src = cv2.imread(\"resources/images/denied.jpeg\")\n",
    "src = cv2.imread(\"resources/images/Arihant/Arihant_3.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:35:59.704956Z",
     "start_time": "2021-03-18T08:35:59.689989Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_percent = 40 # percent of original size\n",
    "#scale_percent = 20 # percent of original size\n",
    "width = int(src.shape[1] * scale_percent / 100)\n",
    "height = int(src.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "src = cv2.resize(src, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:05.036246Z",
     "start_time": "2021-03-18T08:36:05.030246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(604, 604, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:09.764627Z",
     "start_time": "2021-03-18T08:36:08.510214Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"Input\", src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:17.198688Z",
     "start_time": "2021-03-18T08:36:17.181659Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DIM = src.shape[0]\n",
    "\n",
    "img = np.zeros((height, width, 3), dtype = \"uint8\") \n",
    "\n",
    "# Creating a polyline with the 5 points depicting left eye, right eye, tip of nose, left lip corner, right lip corner\n",
    "points = np.array([[[0.31556875000000000 * DIM, 0.4615741071428571* DIM], [0.68262291666666670 * DIM, 0.4615741071428571 * DIM], [0.50026249999999990 * DIM, 0.6405053571428571 * DIM], [0.34947187500000004 * DIM, 0.8246919642857142 * DIM], [0.65343645833333330 * DIM, 0.8246919642857142* DIM]]], np.int32)\n",
    "cv2.polylines(img, [points], True, (255, 255, 255), thickness=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:32.785483Z",
     "start_time": "2021-03-18T08:36:32.765490Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.imwrite( \"resources/images/denied.jpeg\", src )\n",
    "\n",
    "cv2.imwrite( \"resources/images/Arihant/Arihant_3.jpeg\", src )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:35.607049Z",
     "start_time": "2021-03-18T08:36:35.602054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(604, 604, 3)\n",
      "(604, 604, 3)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(src))\n",
    "print(np.shape(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:40.718247Z",
     "start_time": "2021-03-18T08:36:40.710202Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = mymodel1.Predict(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:43.129782Z",
     "start_time": "2021-03-18T08:36:43.123792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print (type(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:45.377603Z",
     "start_time": "2021-03-18T08:36:45.373575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:48.766523Z",
     "start_time": "2021-03-18T08:36:48.763522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.21980047]]\n",
      "\n",
      "  [[0.6314893 ]]\n",
      "\n",
      "  [[0.50563276]]\n",
      "\n",
      "  [[0.6201441 ]]\n",
      "\n",
      "  [[0.29651093]]\n",
      "\n",
      "  [[0.7466994 ]]\n",
      "\n",
      "  [[0.2907535 ]]\n",
      "\n",
      "  [[0.8409446 ]]\n",
      "\n",
      "  [[0.4480784 ]]\n",
      "\n",
      "  [[0.84456635]]]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:51.671590Z",
     "start_time": "2021-03-18T08:36:51.666620Z"
    }
   },
   "outputs": [],
   "source": [
    "l_eye = tuple([int(DIM*i) for i in (predictions[0,0,0,0], predictions[0,1,0,0])])   \n",
    "r_eye = tuple([int(DIM*i) for i in (predictions[0,2,0,0], predictions[0,3,0,0])]) \n",
    "nose = tuple([int(DIM*i) for i in (predictions[0,4,0,0], predictions[0,5,0,0])]) \n",
    "l_lip = tuple([int(DIM*i) for i in (predictions[0,6,0,0], predictions[0,7,0,0])]) \n",
    "r_lip = tuple([int(DIM*i) for i in (predictions[0,8,0,0], predictions[0,9,0,0])]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:53.712375Z",
     "start_time": "2021-03-18T08:36:53.707362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(132, 381)\n",
      "(305, 374)\n",
      "(179, 451)\n",
      "(175, 507)\n",
      "(270, 510)\n"
     ]
    }
   ],
   "source": [
    "print(l_eye)\n",
    "print(r_eye)\n",
    "print(nose)\n",
    "print(l_lip)\n",
    "print(r_lip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:36:58.012454Z",
     "start_time": "2021-03-18T08:36:58.001811Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[208, 211, 209],\n",
       "        [208, 211, 209],\n",
       "        [208, 211, 209],\n",
       "        ...,\n",
       "        [197, 200, 198],\n",
       "        [198, 201, 199],\n",
       "        [200, 203, 201]],\n",
       "\n",
       "       [[208, 211, 209],\n",
       "        [208, 211, 209],\n",
       "        [208, 211, 209],\n",
       "        ...,\n",
       "        [197, 200, 198],\n",
       "        [197, 200, 198],\n",
       "        [198, 201, 199]],\n",
       "\n",
       "       [[208, 211, 209],\n",
       "        [208, 211, 209],\n",
       "        [208, 211, 209],\n",
       "        ...,\n",
       "        [199, 202, 200],\n",
       "        [197, 200, 198],\n",
       "        [197, 200, 198]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[169, 179, 189],\n",
       "        [169, 179, 189],\n",
       "        [169, 179, 189],\n",
       "        ...,\n",
       "        [194, 205, 209],\n",
       "        [195, 206, 210],\n",
       "        [196, 207, 211]],\n",
       "\n",
       "       [[169, 179, 189],\n",
       "        [169, 179, 189],\n",
       "        [169, 179, 189],\n",
       "        ...,\n",
       "        [195, 206, 210],\n",
       "        [195, 206, 210],\n",
       "        [194, 205, 209]],\n",
       "\n",
       "       [[169, 179, 189],\n",
       "        [169, 179, 189],\n",
       "        [169, 179, 189],\n",
       "        ...,\n",
       "        [196, 207, 211],\n",
       "        [197, 208, 212],\n",
       "        [199, 210, 214]]], dtype=uint8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv2.circle(src,l_eye, 1, (0,0,255), -1)\n",
    "cv2.circle(src,l_eye, 3, (0,0,255), -1)\n",
    "cv2.circle(src,r_eye, 3, (0,0,255), -1)\n",
    "cv2.circle(src,nose, 3, (0,0,255), -1)\n",
    "cv2.circle(src,l_lip, 3, (0,0,255), -1)\n",
    "cv2.circle(src,r_lip, 3, (0,0,255), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:37:01.954483Z",
     "start_time": "2021-03-18T08:37:01.947515Z"
    }
   },
   "outputs": [],
   "source": [
    "scale_percent = 100 # percent of original size\n",
    "#scale_percent = 20 # percent of original size\n",
    "width = int(src.shape[1] * scale_percent / 100)\n",
    "height = int(src.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "# resize image\n",
    "src = cv2.resize(src, dim, interpolation = cv2.INTER_AREA)\n",
    "img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:37:27.461855Z",
     "start_time": "2021-03-18T08:37:07.069464Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imshow(\"Input\", src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:17:06.937963Z",
     "start_time": "2021-03-18T08:17:06.922960Z"
    }
   },
   "outputs": [],
   "source": [
    "src = src\n",
    "\n",
    "rows,cols,ch = src.shape\n",
    "\n",
    "pts1 = np.float32([l_eye,r_eye,l_lip,r_lip])\n",
    "pts2 = np.float32([[DIM*0.31556875000000000, DIM*0.4615741071428571],\\\n",
    "                   [DIM*0.68262291666666670, DIM*0.4615741071428571],\\\n",
    "                   [DIM*0.34947187500000004, DIM*0.8246919642857142],\\\n",
    "                   [DIM*0.65343645833333330, DIM*0.8246919642857142]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "\n",
    "dst = cv2.warpPerspective(src,M, (width,height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:17:10.655754Z",
     "start_time": "2021-03-18T08:17:10.650748Z"
    }
   },
   "outputs": [],
   "source": [
    "background = img\n",
    "overlay = dst\n",
    "print(np.shape(background))\n",
    "print(np.shape(overlay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:17:14.544544Z",
     "start_time": "2021-03-18T08:17:14.530545Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "added_image = cv2.addWeighted(background,0.1,overlay,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:17:19.261470Z",
     "start_time": "2021-03-18T08:17:17.078624Z"
    }
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Source image', src)\n",
    "cv2.imshow('Warp', dst)\n",
    "#cv2.imshow('dark', img) \n",
    "#cv2.imshow('Warp + Overlay', added_image)\n",
    "\n",
    "cv2.imwrite( \"images/Arvin/Avbox_1.jpeg\", dst )\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reidentification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:17:26.483558Z",
     "start_time": "2021-03-18T08:17:25.551339Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from utils.opv import OpvModel\n",
    "\n",
    "mymodel2 = OpvModel(\"face-reidentification-retail-0095\", device=\"CPU\", fp=\"FP32\")\n",
    "#mymodel = OpvModel(\"face-reidentification-retail-0095\", device=\"MYRIAD\", fp=\"FP16\", ncs=1)\n",
    "#mymodel2 = OpvModel(\"face-reidentification-retail-0095\", device=\"CPU\", fp=\"FP32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:05.476276Z",
     "start_time": "2021-03-18T08:18:05.410183Z"
    }
   },
   "outputs": [],
   "source": [
    "aface1 = cv2.imread(\"resources/images/Arihant/Abox_4.jpeg\")\n",
    "aface2 = cv2.imread(\"resources/images/Arihant/Abox_6.jpeg\")\n",
    "aface3 = cv2.imread(\"resources/images/Arihant/Abox_8.jpeg\")\n",
    "dface1 = cv2.imread(\"resources/images/Daniel/Dbox_1.jpeg\")\n",
    "dface2 = cv2.imread(\"resources/images/Daniel/Dbox_2.jpeg\")\n",
    "dface3 = cv2.imread(\"resources/images/Daniel/Dbox_3.jpeg\")\n",
    "avface1 = cv2.imread(\"resources/images/Arvin/Avbox_1.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:08.116558Z",
     "start_time": "2021-03-18T08:18:08.046535Z"
    }
   },
   "outputs": [],
   "source": [
    "predictiona1 = mymodel2.Predict(aface1)\n",
    "predictiona2 = mymodel2.Predict(aface2)\n",
    "predictiona3 = mymodel2.Predict(aface3)\n",
    "\n",
    "predictiond1 = mymodel2.Predict(dface1)\n",
    "predictiond2 = mymodel2.Predict(dface2)\n",
    "predictiond3 = mymodel2.Predict(dface3)\n",
    "\n",
    "predictionav1 = mymodel2.Predict(avface1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:12.610192Z",
     "start_time": "2021-03-18T08:18:12.606197Z"
    }
   },
   "outputs": [],
   "source": [
    "predictiona1_flat = predictiona1.flatten()\n",
    "predictiona1_flat = predictiona1_flat.reshape(1, 256)\n",
    "\n",
    "predictiona2_flat = predictiona2.flatten()\n",
    "predictiona2_flat = predictiona2_flat.reshape(1, 256)\n",
    "\n",
    "predictiona3_flat = predictiona3.flatten()\n",
    "predictiona3_flat = predictiona3_flat.reshape(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:15.276141Z",
     "start_time": "2021-03-18T08:18:15.272112Z"
    }
   },
   "outputs": [],
   "source": [
    "predictiond1_flat = predictiond1.flatten()\n",
    "predictiond1_flat = predictiond1_flat.reshape(1, 256)\n",
    "\n",
    "predictiond2_flat = predictiond2.flatten()\n",
    "predictiond2_flat = predictiond2_flat.reshape(1, 256)\n",
    "\n",
    "predictiond3_flat = predictiond3.flatten()\n",
    "predictiond3_flat = predictiond3_flat.reshape(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:18.215513Z",
     "start_time": "2021-03-18T08:18:18.210509Z"
    }
   },
   "outputs": [],
   "source": [
    "predictionav1_flat = predictionav1.flatten()\n",
    "predictionav1_flat = predictionav1_flat.reshape(1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:21.290529Z",
     "start_time": "2021-03-18T08:18:21.273532Z"
    }
   },
   "outputs": [],
   "source": [
    "cosim_a1_a1 = cosine_similarity(predictiona1_flat, predictiona1_flat)\n",
    "cosim_a1_a2 = cosine_similarity(predictiona1_flat, predictiona2_flat)\n",
    "cosim_a1_a3 = cosine_similarity(predictiona1_flat, predictiona3_flat)\n",
    "\n",
    "cosim_d1_d1 = cosine_similarity(predictiond1_flat, predictiond1_flat)\n",
    "cosim_d1_d2 = cosine_similarity(predictiond1_flat, predictiond2_flat)\n",
    "cosim_d1_d3 = cosine_similarity(predictiond1_flat, predictiond3_flat)\n",
    "\n",
    "cosim_a1_d1 = cosine_similarity(predictiona1_flat, predictiond1_flat)\n",
    "cosim_a1_d2 = cosine_similarity(predictiona1_flat, predictiond2_flat)\n",
    "cosim_a1_d3 = cosine_similarity(predictiona1_flat, predictiond3_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:18:23.095121Z",
     "start_time": "2021-03-18T08:18:23.089119Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cosim_a1_a1)\n",
    "print(cosim_a1_a2)\n",
    "print(cosim_a1_a3)\n",
    "\n",
    "print(cosim_d1_d1)\n",
    "print(cosim_d1_d2)\n",
    "print(cosim_d1_d3)\n",
    "\n",
    "print(cosim_a1_d1)\n",
    "print(cosim_a1_d2)\n",
    "print(cosim_a1_d3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the  vector files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:19:01.689819Z",
     "start_time": "2021-03-18T08:19:01.678786Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "with open('arihant.pickle', 'wb') as f:\n",
    "    pickle.dump(predictiona1_flat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:19:04.422272Z",
     "start_time": "2021-03-18T08:19:04.401242Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('daniel.pickle', 'wb') as f:\n",
    "    pickle.dump(predictiond1_flat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:19:06.768718Z",
     "start_time": "2021-03-18T08:19:06.762690Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('arvin.pickle', 'wb') as f:\n",
    "    pickle.dump(predictionav1_flat, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:20:12.148582Z",
     "start_time": "2021-03-18T08:20:09.330475Z"
    }
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "def DrawBoundingBoxes(predictions, image, conf=0.5):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions = predictions[0][0]\n",
    "    confidence = predictions[:,2]\n",
    "    topresults = predictions[(confidence>conf)]\n",
    "    (h,w) = canvas.shape[:2]\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h])\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return canvas\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    predictions = mymodel0.Predict(frame)\n",
    "    face_box\n",
    "    predictions1 = mymodel1.Predict(face_box)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit',DrawBoundingBoxes(predictions,frame))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
