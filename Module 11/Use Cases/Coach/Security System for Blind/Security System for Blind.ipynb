{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "60E4QunViemt"
   },
   "source": [
    "# Welcome to 'Security system for the blind'\n",
    "\n",
    "Currently, it is difficult for blind people to tell who is at their door without the help of an external system. They are capable of hearing but with voice recording and maniupulation there is a window of opportunity for people to take advantage of them. We will be using face recognition with a security camera to detect people and try to identify their faces. We will then be using the 'pyttsx3' to convert the name of the person detected to speech for the blind person. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M8vvCEiJiemu"
   },
   "source": [
    "In order to detect the faces from the security camera we will be using the 'face-detection-adas', 'face-reidentification-retail-0095', 'landmarks-regression-retail-0009' pre-trained models from the OpenVINO model zoo. You can find out more about it here ->https://docs.openvinotoolkit.org/2019_R1/usergroup1.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:21:54.109846Z",
     "start_time": "2021-03-19T07:21:52.403351Z"
    },
    "id": "845uefAViemv",
    "outputId": "54bd2834-132b-4eff-ecdd-2c8de39c888c"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils.opv import OpvModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDPYa2sSiem2"
   },
   "source": [
    "## Task: Load the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:21:57.968238Z",
     "start_time": "2021-03-19T07:21:56.518530Z"
    },
    "id": "pwczAr2Oiem2"
   },
   "outputs": [],
   "source": [
    "mymodel0 = OpvModel(\"face-detection-adas-0001\", device=\"CPU\", fp=\"FP16\")\n",
    "mymodel1 = OpvModel(\"landmarks-regression-retail-0009\", device=\"CPU\", fp=\"FP32\")\n",
    "mymodel2 = OpvModel(\"face-reidentification-retail-0095\", device=\"CPU\", fp=\"FP32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7IHppAVaiem8"
   },
   "source": [
    "## Task: The main code\n",
    "\n",
    "Here is the main code. It turns on our webcam, capture an image upon user request, process that image by calling other user-defined functions, and compare the resulting vector into our vector database. \n",
    "\n",
    "This code should be activated the last, after running the tabs below it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:23:40.571025Z",
     "start_time": "2021-03-19T07:23:13.846980Z"
    },
    "id": "u1BWbuc0iem9"
   },
   "outputs": [],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Security Camera\")\n",
    "img_counter = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "#     global frame\n",
    "       \n",
    "    cv2.putText(frame, 'Press Spacebar!', (50, 100), # include text\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255,255), 2)  \n",
    "    cv2.imshow(\"Security Camera\", frame)   \n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    k = cv2.waitKey(1)\n",
    "    \n",
    "    if k%256 == 27: # ESC pressed       \n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "\n",
    "        \n",
    "        img_name = \"image_{}\".format(img_counter)\n",
    "        #cv2.imwrite(img_name, frame)\n",
    "        print(\"{} captured!\".format(img_name))\n",
    "        try:\n",
    "            predictions = mymodel0.Predict(frame)        \n",
    "            DrawBoundingBoxes(predictions,frame)\n",
    "            WarpPhoto(face_box) \n",
    "            GetVec(dst)\n",
    "            cosim(prediction1_flat)\n",
    "        except:\n",
    "            print(\"There is no recognized face detected\")\n",
    "        img_counter += 1\n",
    "        \n",
    "cam.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "994J7DV4ienC"
   },
   "source": [
    "## Task: Draw Bounding Box around the Face\n",
    "\n",
    "We create a function to draw a bounding box around the face image that has been detected by face-detection-adas-0001.\n",
    "\n",
    "Additionally, we will store the captured image of a face into the variable face_box for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:03.449872Z",
     "start_time": "2021-03-19T07:22:03.437909Z"
    },
    "id": "hYWRtHvdienD"
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=.2):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # \n",
    "    for detection in topresults:\n",
    "        \n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "        cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    \n",
    "    global face_box\n",
    "    face_box = canvas[ymin:ymax,xmin:xmax]\n",
    "    \n",
    "    cv2.imshow(\"face_box\",face_box)\n",
    "    cv2.waitKey(10)         \n",
    "    #Show result image for 0,5 sec on screen\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cm3mlPXqienO"
   },
   "source": [
    "## Task: Create a Function to Warp Photo Given the Reference Points\n",
    "\n",
    "Here, we create a function that does several things:\n",
    "- find out the 5 landmarks within the face image: left and right eyes, nose, left and right corner of lips\n",
    "- using perspective transformation to warp the photo into the format required by the face reidentification model\n",
    "- store the new image in the variable called dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:07.655628Z",
     "start_time": "2021-03-19T07:22:07.640594Z"
    },
    "id": "pZKOuz2-ienP"
   },
   "outputs": [],
   "source": [
    "def WarpPhoto(src):\n",
    "    predictions = mymodel1.Predict(src)\n",
    "    \n",
    "    DIM = src.shape[0] \n",
    "    \n",
    "    l_eye = tuple([int(DIM*i) for i in (predictions[0,0,0,0], predictions[0,1,0,0])])   \n",
    "    r_eye = tuple([int(DIM*i) for i in (predictions[0,2,0,0], predictions[0,3,0,0])]) \n",
    "    nose = tuple([int(DIM*i) for i in (predictions[0,4,0,0], predictions[0,5,0,0])]) \n",
    "    l_lip = tuple([int(DIM*i) for i in (predictions[0,6,0,0], predictions[0,7,0,0])]) \n",
    "    r_lip = tuple([int(DIM*i) for i in (predictions[0,8,0,0], predictions[0,9,0,0])]) \n",
    "    \n",
    "    pts1 = np.float32([l_eye,r_eye,l_lip,r_lip])\n",
    "    pts2 = np.float32([[DIM*0.31556875000000000, DIM*0.4615741071428571],\\\n",
    "                   [DIM*0.68262291666666670, DIM*0.4615741071428571],\\\n",
    "                   [DIM*0.34947187500000004, DIM*0.8246919642857142],\\\n",
    "                   [DIM*0.65343645833333330, DIM*0.8246919642857142]])\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    \n",
    "    global dst\n",
    "    dst = cv2.warpPerspective(src,M, (DIM,DIM))\n",
    "    \n",
    "    cv2.imshow('Warp', dst)\n",
    "    cv2.waitKey(10)\n",
    "    return   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c1gBQJfiene"
   },
   "source": [
    "## Task: Get Face Vector from Warped Photos\n",
    "\n",
    "Once we have the image processed to the format we want, we will now use the face-reidentification model to create a vector corresponding to the processed image. The idea is that every face will have different vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:10.379105Z",
     "start_time": "2021-03-19T07:22:10.372104Z"
    },
    "id": "Ia4vYp-aienf"
   },
   "outputs": [],
   "source": [
    "def GetVec(img):\n",
    "    prediction1 = mymodel2.Predict(img)\n",
    "    \n",
    "    global prediction1_flat\n",
    "    prediction1_flat = prediction1.flatten()\n",
    "    prediction1_flat = prediction1_flat.reshape(1, 256)\n",
    "    \n",
    "    print (prediction1_flat)\n",
    "    \n",
    "    return prediction1_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I97soUkcienw"
   },
   "source": [
    "## Task: Import Vector Database\n",
    "\n",
    "Here, we import our vector database that contains the vector set of person's photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:13.156320Z",
     "start_time": "2021-03-19T07:22:13.149300Z"
    },
    "id": "lpGHWlf8ienx"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./resources/database/arihant.pickle', 'rb') as f:\n",
    "    predictiona1_flat = pickle.load(f)\n",
    "    \n",
    "with open('./resources/database/daniel.pickle', 'rb') as f:\n",
    "    predictiond1_flat = pickle.load(f)\n",
    "    \n",
    "with open('./resources/database/arvin.pickle', 'rb') as f:\n",
    "    predictionav1_flat = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxdG1TnOien9"
   },
   "source": [
    "## Task: Compare Vector with Database and output the name in a sound format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:22:16.589216Z",
     "start_time": "2021-03-19T07:22:16.390145Z"
    },
    "id": "4_-Xcpxnien_"
   },
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "def cosim(vec):\n",
    "    sim = cosine_similarity(vec, predictiond1_flat)\n",
    "    \n",
    "    if cosine_similarity(vec, predictiond1_flat) > 0.5: #if cosine similarity with daniel is high\n",
    "        friends = cv2.imread(\"./resources/images/Daniel/Daniel.jpeg\")\n",
    "        cv2.imshow('It is Daniel', friends)\n",
    "        engine.say(\"It is Daniel\")  # using the engine here\n",
    "        engine.runAndWait()\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    elif cosine_similarity(vec, predictiona1_flat) > 0.5: #if cosine similarity with Arihant is high\n",
    "        friends = cv2.imread(\"./resources/images/Arihant/Arihant.jpeg\")\n",
    "        cv2.imshow('It is Arihant', friends)\n",
    "        engine.say(\"It is Arihant\")\n",
    "        engine.runAndWait()\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    elif cosine_similarity(vec, predictionav1_flat) > 0.5: #if cosine similarity with Arihant is high\n",
    "        friends = cv2.imread(\"./resources/images/Arvin/Arvin.jpg\")\n",
    "        cv2.imshow('It is Arvin', friends)\n",
    "        engine.say(\"It is Arvin\")\n",
    "        engine.runAndWait()\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    else : #if cosine similarity with daniel is high\n",
    "        print(\"Do you belong here?\")\n",
    "        friends = cv2.imread(\"./resources/images/denied.jpeg\")\n",
    "        cv2.imshow('Do you belong here?', friends)\n",
    "        engine.say(\"Not found\")   # using the engine here\n",
    "        engine.runAndWait() \n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Security System for Blind.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
