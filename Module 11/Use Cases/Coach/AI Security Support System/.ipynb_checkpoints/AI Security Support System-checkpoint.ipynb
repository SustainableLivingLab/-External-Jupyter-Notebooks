{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmcEa8ufmwI4"
   },
   "source": [
    "# Welcome to AI security support system\n",
    "\n",
    "Have you ever considered the job of a security officer. In some schools, office buildings and even appartements, there is often one individual who is tasked with observing feeds from multiple security cameras. These security guards are capable of making mistakes. Now let us consider the situation of a theft or burglary. It is important for the security officials to be able to easily notified when there is a person on a video feed. That is what we will be solving today. We will be creating a system that is able to detect if there is a person detected on a video feed and alerting the user about it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maw3JU7omwI6"
   },
   "source": [
    "In order to detect the people from the  camera we will be using the 'person-detection-retail-0013' pre-trained models from the OpenVINO model zoo. You can find out more about it here ->https://docs.openvinotoolkit.org/2019_R1/usergroup1.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:06:09.046190Z",
     "start_time": "2021-03-19T07:06:08.618173Z"
    },
    "id": "h75Y5cWSmwI7"
   },
   "outputs": [],
   "source": [
    "import cv2 #importing all required libraries\n",
    "import numpy as np\n",
    "from utils.opv import OpvModel  \n",
    "import matplotlib.pyplot as plt\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ACivBNjbmwJB"
   },
   "source": [
    "## Task: Load the pretrained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:06:12.838687Z",
     "start_time": "2021-03-19T07:06:11.589692Z"
    },
    "id": "OpGjUQMOmwJD",
    "outputId": "114e9cd0-b5a6-40ad-cc91-981870ad9b0f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "D:\\001 SL2 Notes\\23feb downloaded files\\Github v3\\AI4YExpress\\Use Cases\\Coach\\AI Security Support System\\utils\\opv.py:86: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  self.input_layer = next(iter(net.inputs))\n"
     ]
    }
   ],
   "source": [
    "mymodel2 = OpvModel(\"person-detection-retail-0013\",device=\"CPU\", fp=\"FP16\", ncs=0)\n",
    "#depending on whether you are using Neural Compute Stick you can set the value of ncs to 0 or 1, if not using NCS change device from Myriad to CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gnss4_PpmwJZ"
   },
   "source": [
    "## Task: Draw Bounding Box around the person\n",
    "\n",
    "We create a function to draw a bounding box around the person that has been detected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:06:15.525598Z",
     "start_time": "2021-03-19T07:06:15.513600Z"
    },
    "id": "mn1xRlOhmwJa"
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image): # the input will come from the main code\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    conf = 0\n",
    "    predictions = predictions[0][0]\n",
    "    confidence = predictions[:,2]\n",
    "    topresults = predictions[(confidence>conf)]\n",
    "    (h,w) = canvas.shape[:2]\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")# assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" persons(s) detected\", (50,50),# include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0kj81L0WmwJf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLJDeNHRmwJm"
   },
   "source": [
    "## Task: The main code\n",
    "\n",
    "Here is the main code. It turns on our webcam, capture an image upon user request, process that image by calling other user-defined functions, and compare the resulting vector into our vector database. \n",
    "\n",
    "For this part of the code we will be using a live video feed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:06:39.413213Z",
     "start_time": "2021-03-19T07:06:29.432614Z"
    },
    "id": "ABWPZ2HoZtF-"
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    predictions = mymodel2.Predict(frame)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit',DrawBoundingBoxes(predictions,frame))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0TuZI9VZtGB"
   },
   "source": [
    "Seems that we are drawing far too many boxes. However, not every bounding box may be a face. To see which are valid predictions, we will need to compare the probability scores against a threshold that we set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7ANd9xxmwJq"
   },
   "source": [
    "## Task: Create a threshold.\n",
    "\n",
    "If there is a person detected on the screen then alert the user through a \"beep\" sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:06:56.430128Z",
     "start_time": "2021-03-19T07:06:56.418160Z"
    },
    "id": "LyhzHaqTmwJr"
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf = 0.1): # the predictions and image come from the main code\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions = predictions[0][0]\n",
    "    confidence = predictions[:,2]\n",
    "    topresults = predictions[(confidence>conf)]\n",
    "    (h,w) = canvas.shape[:2]\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")# assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4) # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" persons(s) detected\", (50,50),# include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    if len(topresults) > 0:\n",
    "        winsound.Beep(3000,20)\n",
    "    \n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9fn_LVzZtGF"
   },
   "source": [
    "Let's try again with the modified Confidence interval!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-19T07:07:09.765723Z",
     "start_time": "2021-03-19T07:07:04.165851Z"
    },
    "id": "M-FO5TIgmwJx"
   },
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    predictions = mymodel2.Predict(frame)\n",
    "    \n",
    "    cv2.imshow('Press Spacebar to Exit',DrawBoundingBoxes(predictions,frame))\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GtoGaErqmwJ0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AI Security Support System.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
