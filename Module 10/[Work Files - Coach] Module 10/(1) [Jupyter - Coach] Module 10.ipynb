{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Inference Models\n",
    "*Version 1.0*\n",
    "\n",
    "To navigate up and down, you can use the up and down arrow keys on your keyboard<br />\n",
    "To execute code in this workbook, select the code block and press **Shift+Enter** <br />\n",
    "To edit the code block, press enter. \n",
    "\n",
    "The codes in this workbook are cumulative. (Variables defined continue to be available until the notebook is closed) <br />\n",
    "So do start from the top and work your way down to avoid unexpected results!\n",
    "\n",
    "\n",
    "For more help on using Jupyter Notebook, you can click on Help > User Interface Tour in the menu above, <br />\n",
    "or visit https://jupyter-notebook.readthedocs.io/en/stable/ui_components.html\n",
    "\n",
    "Experiment and test out your ideas, for that is one of the fastest ways to learn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Intel&reg; OpenVINO&trade; Inference Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now switch gears to use some pre-trained CNNs. We heard about CNNs, let us now see them in action. the Intel&reg; OpenVINO&trade; Toolkit ships together with some pre-trained models that you can use. You can also use the Model Optimizer to convert models trained on other frameworks such as Caffe, MxNet, and Tensorflow. The toolkit currently supports running the optimized models on either CPU, GPU, FPGA or MYRIAD (the NCS2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model Optimizer is available at:\n",
    "%OPENVINO_INSTALL_DIR%/Intel/computer_vision_sdk/deployment_tools/model_optimizer \n",
    "\n",
    "You can run the model optimizer by activating the cv environment (where you installed Python 3.6) <br />\n",
    "and run **python mo.py** with the required arguments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the FP32 data type, more commonly used for CPUs:\n",
    "(replace %PATH_TO_MODEL% and %PATH_TO_OUTPUT% accordingly)\n",
    "\n",
    "python mo.py --input_model \"%PATH_TO_MODEL%\\squeezenet1.1.caffemodel\" --output_dir \"%PATH_TO_OUTPUT%/FP32\" --data_type FP32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the FP16 data type, more commonly used for NCS2:\n",
    "\n",
    "(replace %PATH_TO_MODEL% and %PATH_TO_OUTPUT% accordingly)\n",
    "\n",
    "python mo.py --input_model \"%PATH_TO_MODEL%\\squeezenet1.1.caffemodel\" --output_dir \"%PATH_TO_OUTPUT%/FP16\" --data_type FP16\n",
    "\n",
    "\n",
    "To give you a smoother start, some models have already been converted for you in the \"models\" subdirectory\n",
    "\n",
    "Bonus: You can learn more about FP16 and FP32 [here](https://www.quora.com/What-is-the-difference-between-FP16-and-FP32-when-doing-deep-learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Sample Model for Classification (running on CPU)\n",
    "\n",
    "Documentation for the Intel® OpenVINO™ Python API is available [online](https://software.intel.com/en-us/articles/OpenVINO-InferEngine#overview-of-inference-engine-python-api)\n",
    "\n",
    "As of 18 January 2019, the documentation says \"**NOTE: This is a preview version of the Inference Engine Python* API for evaluation purpose only. Module structure and API itself will be changed in future releases.**\"\n",
    "\n",
    "Hence, it is likely that the API will be updated eventually. For now, let us explore how to use it.\n",
    "\n",
    "The Intel® OpenVINO™ installation also comes with a sample python file that performs classification. You can find the file at %OPENVINO_INSTALL_DIR%/Intel/computer_vision_sdk/inference_engine/python_samples/classification_sample.py \n",
    "\n",
    "Alternatively, you can execute the code below, and the results will be displayed. It will first show the neural network being loaded, and then the classification results (beginning with the class labels that have the highest probability).\n",
    "\n",
    "### Classifying between 1000 different image classes with SqueezeNet\n",
    "\n",
    "This model has been trained to recognize images from 1000 classes. You can read more about the project  [here](https://arxiv.org/abs/1602.07360).\n",
    "\n",
    "Next, let us try to make use of this model to make some classifications.\n",
    "\n",
    "Apart from the example below, you can also try a few other images such as images/dog.jpeg, images/hamster.jpeg and images/bluecar.jpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:41:53.788845Z",
     "start_time": "2021-03-18T07:41:52.053148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Loading network files:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classification_sample.py:76: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  assert len(net.inputs.keys()) == 1, \"Sample supports only single input topologies\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tmodels/squeezenet1.1/FP16/squeezenet1.1.xml\n",
      "\tmodels/squeezenet1.1/FP16/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ WARNING ] Image images/cat.jpeg is resized from (1500, 2034) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 7.000207901000977 ms\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image images/cat.jpeg\n",
      "\n",
      "0.7695209 label cat\n",
      "0.1498846 label tabby cat\n",
      "0.0361377 label cat\n",
      "0.0187889 label catamount\n",
      "0.0087181 label cat\n",
      "0.0051658 label terrier\n",
      "0.0016991 label fox, Vulpes vulpes\n",
      "0.0013994 label vat\n",
      "0.0010574 label terrier\n",
      "0.0008215 label cat, Siamese\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classification_sample.py -i images/cat.jpeg -m models/squeezenet1.1/FP16/squeezenet1.1.xml --labels models/squeezenet1.1/FP16/squeezenet1.1.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Classify at least 1 more photo from the folder ./images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:41:59.638516Z",
     "start_time": "2021-03-18T07:41:58.836835Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classification_sample.py:76: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  assert len(net.inputs.keys()) == 1, \"Sample supports only single input topologies\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Loading network files:\n",
      "\tmodels/squeezenet1.1/FP32/squeezenet1.1.xml\n",
      "\tmodels/squeezenet1.1/FP32/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ WARNING ] Image images/bluecar.jpeg is resized from (1416, 2520) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 4.973173141479492 ms\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image images/bluecar.jpeg\n",
      "\n",
      "0.2936813 label wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\n",
      "0.2121303 label radiator grille\n",
      "0.2028320 label minivan\n",
      "0.1301245 label race car, racing car\n",
      "0.1037653 label car, sport car\n",
      "0.0246912 label convertible\n",
      "0.0170834 label wheel\n",
      "0.0068460 label pickup truck\n",
      "0.0042662 label hack, taxi, taxicab\n",
      "0.0023217 label car, coach, carriage\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classification_sample.py -i images/bluecar.jpeg -m models/squeezenet1.1/FP32/squeezenet1.1.xml --labels models/squeezenet1.1/FP32/squeezenet1.1.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do try out more images and explore why some images might be misclassified, especially those with more objects in the background. \n",
    "\n",
    "Next, we will be exploring how to run the same model on the NCS2, a portable USB device that is designed to speed up inference tasks on edge devices. It can also be used on your laptop.\n",
    "\n",
    "\n",
    "### 2.2 Sample model for Classification (running on NCS2)\n",
    "\n",
    "The Neural Compute Stick is intended to make inferences a breeze, especially for larger networks. Let us see how we can run our inference on the NCS2 instead of on our CPU.\n",
    "\n",
    "First, you need to plugin in the NCS2 into a USB port on your computer. If you have a USB3.0 port, use it for faster data transfer speeds. Then you just need to execute the code below.\n",
    "\n",
    "How different is it from the code above?\n",
    "\n",
    "We have added **-d MYRIAD** to specify to use the NCS2 instead of the CPU. (Myriad is actually the name of the powerful chip that is inside the NCS2) And we have also updated the model path to the FP16 directory instead of the FP32 directory. This is because the NCS2 only supports **FP16**, while CPUs tend to use FP32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:04.448549Z",
     "start_time": "2021-03-18T07:42:03.828558Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Loading network files:\n",
      "\tmodels/squeezenet1.1/FP16/squeezenet1.1.xml\n",
      "\tmodels/squeezenet1.1/FP16/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ WARNING ] Image images/cat.jpeg is resized from (1500, 2034) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 4.997491836547852 ms\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image images/cat.jpeg\n",
      "\n",
      "0.7695209 label cat\n",
      "0.1498846 label tabby cat\n",
      "0.0361377 label cat\n",
      "0.0187889 label catamount\n",
      "0.0087181 label cat\n",
      "0.0051658 label terrier\n",
      "0.0016991 label fox, Vulpes vulpes\n",
      "0.0013994 label vat\n",
      "0.0010574 label terrier\n",
      "0.0008215 label cat, Siamese\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classification_sample.py:76: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  assert len(net.inputs.keys()) == 1, \"Sample supports only single input topologies\"\n"
     ]
    }
   ],
   "source": [
    "!python classification_sample.py -d MYRIAD -i images/cat.jpeg -m models/squeezenet1.1/FP16/squeezenet1.1.xml --labels models/squeezenet1.1/FP16/squeezenet1.1.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Classify at least 1 more photo from the folder ./images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:19.633804Z",
     "start_time": "2021-03-18T07:42:18.961778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Loading network files:\n",
      "\tmodels/squeezenet1.1/FP16/squeezenet1.1.xml\n",
      "\tmodels/squeezenet1.1/FP16/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ WARNING ] Image images/dog.jpeg is resized from (717, 800) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 5.003929138183594 ms\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image images/dog.jpeg\n",
      "\n",
      "0.6590434 label beagle\n",
      "0.2003103 label foxhound\n",
      "0.1315307 label hound, Walker foxhound\n",
      "0.0031847 label basset hound\n",
      "0.0022873 label springer spaniel\n",
      "0.0022849 label spaniel\n",
      "0.0006227 label Bernard, St Bernard\n",
      "0.0004176 label gazelle hound\n",
      "0.0000528 label retriever\n",
      "0.0000397 label whippet\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classification_sample.py:76: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  assert len(net.inputs.keys()) == 1, \"Sample supports only single input topologies\"\n"
     ]
    }
   ],
   "source": [
    "!python classification_sample.py -d MYRIAD -i images/dog.jpeg -m models/squeezenet1.1/FP16/squeezenet1.1.xml --labels models/squeezenet1.1/FP16/squeezenet1.1.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probabilities generated on the CPU vs. NCS2 might have some differences due to the way that floating points are supported/calculated. Remeber that we used the FP16 model for the NCS2 and the FP32 model for the CPU. These 2 models are not exactly the same. If you look at the model file sizes in the models subdirectory, you would notice that the .bin file for the FP16 model tends to be much smaller than the .bin file for the FP32 model.\n",
    "\n",
    "Comparing the results on your CPU and on the NCS2, you might only find minor improvements in running time for this Network as it is a small network that runs quickly within 10-20ms. However, as we will see later on, there are some of the Intel Pre-Trained models that can run on the NCS2 that are currently not supported via CPU. But before we go down the rabbit hole, let us pause here and take a look at the code inside classification_sample.py to understand the logic.\n",
    "\n",
    "\n",
    "**After using the model, let us dig deeper into the code**\n",
    "\n",
    "As the code was originally written in C++ for greater efficiency, python wrappers have been created and these are the IEPlugin and IENetwork modules from the openvino.inference_engine package\n",
    "\n",
    "As a start, you might want to open up classification_sample.py to understand the code. The general idea is to:\n",
    "1. Initialize the hardware via IEPlugin (CPU / Myriad / GPU / FPGA)\n",
    "2. Load the network via IENetwork\n",
    "3. Preprocess the input image into the required format\n",
    "4. Make the prediction via exec_net.infer\n",
    "5. Processes/Display the output\n",
    "6. Release Memory. i.e. del plugin, del net and del exec_net. While the del keyword is less commonly seen in python applications, it seems to be required in order to release the load on the NCS2 (when run from the Jupyter Notebook). When it is run directly via command line, there might be automatic release once the script finishes execution.   \n",
    "\n",
    "Before proceeding, do open \"classification_sample.py\" to briefly read through the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Using a Python Class to make things easier\n",
    "\n",
    "Often, we do not really want to implement the lower level codes over and over again. If you recall the previous workshop, once the model was loaded from the sklearn package, there was an awesome method called **model.predict()**. \n",
    "\n",
    "Similarly, can we can just load the CNN model, and then use something similar to model.predict to generate the predictions?\n",
    "\n",
    "Yes, we can.\n",
    "\n",
    "Let us use a helper class from https://github.com/simpledevelopments/OpenVINO-Python-Utils \n",
    "The package has been tested to work on the 2018R5 release of the Intel&reg; OpenVINO&trade; Toolkit. As the Inference Engine Python API is subject to change, our code might need to be updated eventually when the time comes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:38.712683Z",
     "start_time": "2021-03-18T07:42:38.520661Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils.opv import OpvModel      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:42.338160Z",
     "start_time": "2021-03-18T07:42:42.080170Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "D:\\001 SL2 Notes\\23feb downloaded files\\Github v3\\AI4YExpress\\Module 10\\[Work Files - Coach] Module 10\\utils\\opv.py:86: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  self.input_layer = next(iter(net.inputs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model squeezenet1.1 Loaded and Ready on NCS device 1\n"
     ]
    }
   ],
   "source": [
    "# If you encounter the error \"Can not init USB device: NC_DEVICE_NOT_FOUND\", \n",
    "#   check that the NCS2 is plugged into your USB port. \n",
    "#\n",
    "# After you no longer need mymodel to make any more inferences, \n",
    "#   run mymodel.ClearMachine() to release the application from the device.\n",
    "\n",
    "mymodel = OpvModel(\"squeezenet1.1\", device=\"MYRIAD\", fp=\"FP16\", ncs=1, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:50.612507Z",
     "start_time": "2021-03-18T07:42:50.544479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Image resized from (1500, 2034) to (227, 227)\n"
     ]
    }
   ],
   "source": [
    "predictions = mymodel.Predict(cv2.imread(\"images/cat.jpeg\"))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# After you no longer need mymodel to make any more inferences, \n",
    "#   you can run mymodel.ClearMachine() to release the application from the device.\n",
    "#   or wait for automatic cleanup when the python application closes. \n",
    "#   (for Jupyter Notebook, that happens when you use File > Close and Halt)\n",
    "\n",
    "mymodel.ClearMachine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:55.270049Z",
     "start_time": "2021-03-18T07:42:55.254031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.0% chance: Persian cat\n",
      "15.0% chance: tabby, tabby cat\n",
      "3.6% chance: tiger cat\n",
      "1.9% chance: lynx, catamount\n",
      "0.9% chance: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "def displayresults(predictions, labels=None):\n",
    "    if (labels is None):                         # If no labels provided, use numerical labels\n",
    "        labels = np.arange(0,1000).astype(\"str\")\n",
    "    predictions = predictions.reshape(1000)\n",
    "    top5 = predictions.argsort()[-5:][::-1]\n",
    "    top5results = np.column_stack([predictions[top5], labels[top5]])\n",
    "    for (conf, label) in top5results:\n",
    "        print(str(round(float(conf)*100,1))+\"% chance: \"+label)\n",
    "\n",
    "displayresults(predictions,mymodel.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results with section 2.2 that was also run on the NCS2. The results should match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: Revision on NumPy array.\n",
    "See below to find out how to sort and subset NumPy arrays!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:42:59.184082Z",
     "start_time": "2021-03-18T07:42:59.179054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5 2 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4, 5, 2, 1])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:01.349678Z",
     "start_time": "2021-03-18T07:43:01.345677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "np.sort(a)\n",
    "print (np.sort(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:03.607452Z",
     "start_time": "2021-03-18T07:43:03.601457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 3 2 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "np.flip(np.sort(a))\n",
    "print (np.flip(np.sort(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:06.181030Z",
     "start_time": "2021-03-18T07:43:06.176036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4]\n"
     ]
    }
   ],
   "source": [
    "np.flip(np.sort(a))[:2]\n",
    "print (np.flip(np.sort(a))[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:08.630082Z",
     "start_time": "2021-03-18T07:43:08.618096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3]\n"
     ]
    }
   ],
   "source": [
    "print(a.argsort()[-2:][: :-1]) #getting indices of the value 5 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:11.541851Z",
     "start_time": "2021-03-18T07:43:11.536851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4]\n"
     ]
    }
   ],
   "source": [
    "a[a.argsort()[-2:][: :-1]]\n",
    "print(a[a.argsort()[-2:][: :-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.1 How were those results neatly formatted?**\n",
    "\n",
    "Are you wondering what that code did? Let us go step by step,starting from the predictions\n",
    "\n",
    "We are expecting 1000 records, each displaying the probability of the image belonging to that particular class. But predictions.shape shows our array in the form (1,1000,1,1). Hence the first step to reshape it to a 1D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:14.347547Z",
     "start_time": "2021-03-18T07:43:14.343547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1000, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:16.564048Z",
     "start_time": "2021-03-18T07:43:16.561040Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = predictions.reshape(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:18.999111Z",
     "start_time": "2021-03-18T07:43:18.996111Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.2 How do we get the array indices for the top 5 results?**\n",
    "\n",
    "To learn more about numpy, visit https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.argsort.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:22.199931Z",
     "start_time": "2021-03-18T07:43:22.186958Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([283, 281, 282, 287, 285], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argsort()[-5:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.3 What are the probabilities for each of these \"top\" predictions?**\n",
    "\n",
    "They are represented in decimal format (1 means 100% confidence. 0.1 means 10% confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:25.197264Z",
     "start_time": "2021-03-18T07:43:25.190327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76952094, 0.1498846 , 0.0361377 , 0.01878894, 0.00871808],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[predictions.argsort()[-5:][::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.4 And what are the class labels for these predictions?**\n",
    "\n",
    "For this particular example, when we loaded the model, the labels for the different classes were also loaded from the squeezenet1.1.labels (inside the models/squeezenet1.1/FP16 subdirectory) Hence, we can access it using mymodel.labels. Let's just print the first 5 records. You can cross check against the squeezenet1.1.labels file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:28.576104Z",
     "start_time": "2021-03-18T07:43:28.571105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tench, Tinca tinca' 'goldfish, Carassius auratus'\n",
      " 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias'\n",
      " 'tiger shark, Galeocerdo cuvieri' 'hammerhead, hammerhead shark']\n"
     ]
    }
   ],
   "source": [
    "print(mymodel.labels[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.5 Great, but how do we apply the labels to the predictions?**\n",
    "\n",
    "Here are the top 5 results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:31.708452Z",
     "start_time": "2021-03-18T07:43:31.701448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Persian cat', 'tabby, tabby cat', 'tiger cat', 'lynx, catamount',\n",
       "       'Egyptian cat'], dtype='<U121')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.labels[predictions.argsort()[-5:][::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3.6 Now how might we combine both the probabilities and the results into an array?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:35.389465Z",
     "start_time": "2021-03-18T07:43:35.384464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0.76952094', 'Persian cat'],\n",
       "       ['0.1498846', 'tabby, tabby cat'],\n",
       "       ['0.036137696', 'tiger cat'],\n",
       "       ['0.018788941', 'lynx, catamount'],\n",
       "       ['0.008718076', 'Egyptian cat']], dtype='<U121')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top5 = predictions.argsort()[-5:][::-1]\n",
    "np.column_stack([    predictions[top5],    mymodel.labels[top5]     ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2.3.7 Here's everything put together again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:39.334976Z",
     "start_time": "2021-03-18T07:43:39.325987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77.0% chance: Persian cat\n",
      "15.0% chance: tabby, tabby cat\n",
      "3.6% chance: tiger cat\n",
      "1.9% chance: lynx, catamount\n",
      "0.9% chance: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "def displayresults(predictions, labels=None):\n",
    "    if (labels is None):                         # If no labels provided, use numerical labels\n",
    "        labels = np.arange(0,1000).astype(\"str\")\n",
    "    predictions = predictions.reshape(1000)\n",
    "    top5 = predictions.argsort()[-5:][::-1]\n",
    "    top5results = np.column_stack([predictions[top5], labels[top5]])\n",
    "    for (conf, label) in top5results:\n",
    "        print(str(round(float(conf)*100,1))+\"% chance: \"+label)\n",
    "displayresults(predictions,mymodel.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Putting it all together, make predictions about another image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:42.841916Z",
     "start_time": "2021-03-18T07:43:42.751884Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Image resized from (1416, 2520) to (227, 227)\n",
      "29.4% chance: beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon\n",
      "21.2% chance: grille, radiator grille\n",
      "20.3% chance: minivan\n",
      "13.0% chance: racer, race car, racing car\n",
      "10.4% chance: sports car, sport car\n"
     ]
    }
   ],
   "source": [
    "predictions = mymodel.Predict(cv2.imread(\"images/bluecar.jpeg\"))\n",
    "displayresults(predictions, mymodel.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done! You have successfully performed classification, making use of the pre-trained SqueezeNet1.1 and OpenVINO. Take some time to think about the process of loading the models, performing the classification and displaying the results. You can write your notes in your student activity guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Library of Inference Models\n",
    "\n",
    "Remember that there are different types of inference models. Some do image classification, some do object detection or even image segmentation. Intel also provides a set of pre-trained inference models together with the Intel® OpenVINO™ installation. You can find out more about the pre-trained models at\n",
    "https://software.intel.com/en-us/openvino-toolkit/documentation/pretrained-models\n",
    "\n",
    "**Optimizing models into the IR format**<br />\n",
    "At the beginning of section 2, we briefly talked about the Model Optimizer. Before Trained Models are run on the Intel® OpenVINO™ Inference Engine, they need to be optimized into an Intermediate Representation (IR) format. In this way, models trained on frameworks such as Caffe, MxNet, and Tensorflow can be converted into the IR format that can be efficiently run using the toolkit. For more details, refer to https://software.intel.com/en-us/articles/OpenVINO-ModelOptimizer\n",
    "\n",
    "**Pre-Trained models in IR format**<br />\n",
    "The good news is, for the pre-trained Intel models, they have already been converted into the IR format which means they are ready to be used straight out of the box. These can be found at %OPENVINO_INSTALL_DIR%/Intel/computer_vision_sdk/deployment_tools/intel_models\n",
    "\n",
    "\n",
    "To use any of those models, you can just copy the respective subfolders into the models subdirectory where this notebook is located."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Face Detection using a model from the Intel Models \"Library\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do digital cameras detect peoples' faces? Can we also do something like that?\n",
    "\n",
    "<img src=\"images/friendsfaces.png\" style=\"width:400px; float:left;\" />\n",
    "<div style=\"clear:both;\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us make use of the **face-detection-adas-0001** model to help us do just that!\n",
    "\n",
    "### Task: Refer to the model documentation, note down the input and output of the model. \n",
    "\n",
    "You can refer to the documentation for this model at %OPENVINO_INSTALL_DIR%/Intel/computer_vision_sdk/deployment_tools/intel_models/face-detection-adas-0001/description/face-detection-adas-0001.html\n",
    "\n",
    "The network (model) outputs a blob with the shape: [1, 1, N, 7], where N is the number of detected bounding boxes. For each detection, the description has the format: [image_id, label, conf, x_min, y_min, x_max, y_max] (See the 7 variables? That accounts for the 7 in [1,1,N,7])\n",
    "\n",
    "**Copy the folder \"face-detection-adas-0001\" from intel_models into your models folder, then let's get started!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:49.120993Z",
     "start_time": "2021-03-18T07:43:48.550992Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from utils.opv import OpvModel\n",
    "\n",
    "mymodel2 = OpvModel(\"face-detection-adas-0001\",device=\"MYRIAD\", fp=\"FP16\", ncs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:55.772257Z",
     "start_time": "2021-03-18T07:43:55.650193Z"
    }
   },
   "outputs": [],
   "source": [
    "friends = cv2.imread(\"images/friends.jpeg\")\n",
    "friends = cv2.resize(friends,(1200,710))     #Downsize the image since the original is quite large\n",
    "predictions = mymodel2.Predict(friends)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:43:59.005060Z",
     "start_time": "2021-03-18T07:43:59.000060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 200, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the shape you've obtained with the output shape presented in the documentation document. You should get the same shape!\n",
    "\n",
    "How many predictions are there, can you see?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 200 entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, do you wonder what is included in the predictions variable? \n",
    "\n",
    "### Task: List down at least 3 result of the prediction. Notice how they are labelled [image_id, label, conf, x_min, y_min, x_max, y_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:02.923913Z",
     "start_time": "2021-03-18T07:44:02.919914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.         1.         1.         0.7941595  0.39807257 0.84158474\n",
      "    0.5066318 ]\n",
      "   [0.         1.         0.99999964 0.35023394 0.4601197  0.39078203\n",
      "    0.54258573]\n",
      "   [0.         1.         0.995613   0.5246759  0.4436372  0.5696493\n",
      "    0.5426169 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[:,:,0:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, it is now time to draw our bounding box! Try the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:10.987740Z",
     "start_time": "2021-03-18T07:44:08.824418Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=0):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # \n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return canvas\n",
    "\n",
    "cv2.imshow(\"Friends2\",DrawBoundingBoxes(predictions,friends))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh, seems that we are drawing far too many boxes. It appears that we have detected 200 bounding boxes. However, not every bounding box may be a face. To see which are valid predictions, we will need to compare the probability scores against a threshold that we set. \n",
    "\n",
    "### Task: Use 50% confidence as our threshold. \n",
    "\n",
    "Recall how we displayed the results for the classification example, and compare how the code below works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:16.875005Z",
     "start_time": "2021-03-18T07:44:15.487877Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=0.5):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # setting the variable h and w according to image height\n",
    "    \n",
    "    #\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return predictions_1, canvas\n",
    "\n",
    "predictions_1,x = DrawBoundingBoxes(predictions,friends)\n",
    "cv2.imshow(\"Friends2\",x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what do you see? You see that only our friends' faces are put in the box!\n",
    "\n",
    "Now, time to test your understanding of the code. \n",
    "\n",
    "### Task: Print our confidence variable. What does this variable contain? Can you notice the confidence level referring to the four friends on the image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:20.515517Z",
     "start_time": "2021-03-18T07:44:20.509487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.99999964 0.995613   0.9652485  0.01954743 0.01897\n",
      " 0.01794285 0.01770019 0.01764668 0.01762706 0.01760948 0.01733033\n",
      " 0.01699277 0.01693124 0.01667533 0.01658139 0.01621212 0.01598534\n",
      " 0.01597151 0.01589353 0.01587603 0.01585954 0.0157343  0.01567846\n",
      " 0.01560694 0.01541478 0.01540966 0.01534925 0.01514687 0.01509109\n",
      " 0.01504166 0.01500522 0.01474103 0.01465905 0.01453098 0.01449705\n",
      " 0.01445426 0.01443859 0.01428939 0.01418992 0.01384501 0.01382888\n",
      " 0.01380085 0.01380065 0.01364381 0.01363704 0.01353544 0.01353053\n",
      " 0.01335032 0.01334384 0.01331454 0.01328487 0.013275   0.01315907\n",
      " 0.01310862 0.01310846 0.0130723  0.01304318 0.013037   0.01303306\n",
      " 0.01297616 0.01292788 0.01288897 0.01287341 0.01286597 0.01282119\n",
      " 0.01280037 0.01278293 0.01277385 0.01276269 0.01272041 0.01269993\n",
      " 0.01265147 0.01264625 0.01263556 0.01261097 0.01256744 0.01253751\n",
      " 0.01253316 0.01247997 0.01228531 0.01223279 0.01223093 0.01219886\n",
      " 0.01218053 0.01211948 0.01201286 0.01199868 0.01191018 0.01189887\n",
      " 0.01187104 0.01185943 0.0118586  0.01180838 0.0117882  0.01177936\n",
      " 0.01176123 0.01173515 0.01172299 0.01171471 0.01167116 0.01165923\n",
      " 0.01165292 0.01164906 0.01163854 0.01162786 0.01161231 0.0115907\n",
      " 0.01156734 0.01154652 0.01153835 0.01152953 0.01149731 0.01147618\n",
      " 0.0114069  0.01136895 0.01125534 0.01123353 0.01121656 0.01121186\n",
      " 0.01120941 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "confidence = predictions_1[:,2]\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Print topresults variable. What does it contain? \n",
    "Identify again [image_id, label, conf, x_min, y_min, x_max, y_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:24.357388Z",
     "start_time": "2021-03-18T07:44:24.353423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         1.         1.         0.7941595  0.39807257 0.84158474\n",
      "  0.5066318 ]\n",
      " [0.         1.         0.99999964 0.35023394 0.4601197  0.39078203\n",
      "  0.54258573]\n",
      " [0.         1.         0.995613   0.5246759  0.4436372  0.5696493\n",
      "  0.5426169 ]\n",
      " [0.         1.         0.9652485  0.14379883 0.32845277 0.1896973\n",
      "  0.41683376]]\n"
     ]
    }
   ],
   "source": [
    "topresults = predictions_1[(confidence>0.5)]\n",
    "print(topresults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Print out detection [3:7]\n",
    "What does it refer to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:27.028420Z",
     "start_time": "2021-03-18T07:44:27.022418Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7941595 , 0.39807257, 0.84158474, 0.5066318 ], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detection = topresults[0]\n",
    "detection [3:7]\n",
    "# answer: it refers to x_min, y_min, x_max, y_max value from the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: print the variable box. \n",
    "What does it refer to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:29.994807Z",
     "start_time": "2021-03-18T07:44:29.989776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 952.99136639  282.6315251  1009.90169048  359.70857203]\n"
     ]
    }
   ],
   "source": [
    "(h,w) = x.shape[:2] \n",
    "box = detection[3:7] * np.array([w, h, w, h])\n",
    "print (box)\n",
    "# answer: it refers to the x_min, y_min, x_max, y_max position on the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afterwards, you will proceed with drawing the bounding box and the text label. \n",
    "\n",
    "### Task: Draw the bounding box again with your own settings. \n",
    "This time, change the color and thickness of the box, and the size and type of the font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:35.369643Z",
     "start_time": "2021-03-18T07:44:34.019942Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=0.5):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # setting the variable h and w according to image height\n",
    "    \n",
    "    #\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (100, 150, 255), 2)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_TRIPLEX, 0.8, (255, 230,40), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" friend(s) detected. It's time to party!\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_COMPLEX, 0.6, (255, 10,110), 2)\n",
    "    return predictions_1, canvas\n",
    "\n",
    "predictions_1,x = DrawBoundingBoxes(predictions,friends)\n",
    "cv2.imshow(\"Friends2\",x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Use the model to classify and draw a bounding box on another image!\n",
    "Try images with people facing sideways, making funny faces, etc. What do you notice about the ability of the pre-trained model to look for faces?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:38.735396Z",
     "start_time": "2021-03-18T07:44:38.415471Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 200, 7)\n"
     ]
    }
   ],
   "source": [
    "friends = cv2.imread(\"images/friendsinsuit.jpg\") #Use another image!\n",
    "friends = cv2.resize(friends,(1200,710))     #Downsize the image since the original is quite large\n",
    "predictions = mymodel2.Predict(friends)\n",
    "print(predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:45.324946Z",
     "start_time": "2021-03-18T07:44:43.980248Z"
    }
   },
   "outputs": [],
   "source": [
    "def DrawBoundingBoxes(predictions, image, conf=0.5):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions_1 = predictions[0][0]                 # subset dataframe\n",
    "    confidence = predictions_1[:,2]                   # getting conf value [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "    topresults = predictions_1[(confidence>conf)]     # choosing only predictions with conf value bigger than treshold\n",
    "    (h,w) = canvas.shape[:2]                        # setting the variable h and w according to image height\n",
    "    \n",
    "    #\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h]) # determine box location\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\") # assign box location value to xmin, ymin, xmax, ymax\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)  # make a rectangle\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50), # include text\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return predictions_1, canvas\n",
    "\n",
    "predictions_1,x = DrawBoundingBoxes(predictions,friends)\n",
    "cv2.imshow(\"Friends2\",x)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have just built your first face detector!\n",
    "\n",
    "## It's now time for you to do some hands on! \n",
    "\n",
    "You have just used 2 very powerful pre-trained models. One does image classification between 1000 classes of objects, and one does face detection.\n",
    "\n",
    "As you explore different pre-trained models provided in the Intel® Distribution of OpenVINO™ Toolkit, look into the intel_models subdirectory and into the description subfolder of the respective models. The documentation there will give you a better idea of what the respective models are capable of predicting. Once you have done the predictions, it is back to making use of your basic image processing skills to display the results.\n",
    "\n",
    "Whatever you build, keep in mind your purpose and objective and think of different possible approaches. As always, also keep in mind the possible impacts when a machine learning algorithm makes a misclassification and plan for ways to mitigate the risks. For example, what is the worst possible consequence of detecting a face when there is actually no face? Or not detecting a face when it is actually there? As with other scenarios where there may be a probability of error, explore complementing the design of your real-world solutions with other techniques or perhaps even hardware sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1: Blur images/dog.jpeg using what you learnt in section 1\n",
    "Do you also know how to make the blur effect more or less blur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:50.172093Z",
     "start_time": "2021-03-18T07:44:48.542958Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Let's quickly recap the code to read in an image\n",
    "image = cv2.imread(\"images/dog.jpeg\")\n",
    "\n",
    "# We convert it to greyscale to illustrate 2D convolutions.\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "kernel1 = np.ones((19,19),np.float32)/361      # a 19x19 convolution filter\n",
    "filter1 = cv2.filter2D(gray,-1,kernel1)\n",
    "\n",
    "kernel2 = np.ones((3,3),np.float32)/9     # a 3x3 convolution filter\n",
    "filter2 = cv2.filter2D(gray,-1,kernel2)\n",
    "\n",
    "kernel3 = np.ones((50,50),np.float32)/2500     # a 50x50 convolution filter\n",
    "filter3 = cv2.filter2D(gray,-1,kernel3)\n",
    "\n",
    "cv2.imshow(\"Original Greyscale Image\",gray)\n",
    "cv2.imshow(\"Filter1\",filter1)\n",
    "cv2.imshow(\"Filter2\",filter2)\n",
    "cv2.imshow(\"Filter3\",filter3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2: Modify the code in section 2.3 to give the top 3 results instead of top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:53.757063Z",
     "start_time": "2021-03-18T07:44:53.328052Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Machine Released\n",
      "[INFO] Model face-detection-adas-0001 Loaded and Ready on NCS device 1\n"
     ]
    }
   ],
   "source": [
    "mymodel2 = OpvModel(\"face-detection-adas-0001\", device=\"MYRIAD\", fp=\"FP16\", ncs=1, debug=True)\n",
    "# (self, model_name, device, fp=\"FP32\", debug=False, ncs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:44:59.976627Z",
     "start_time": "2021-03-18T07:44:59.971596Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0, 4, 3, ..., 6, 1, 2],\n",
       "         [0, 4, 6, ..., 5, 2, 1],\n",
       "         [0, 4, 6, ..., 5, 2, 1],\n",
       "         ...,\n",
       "         [0, 1, 2, ..., 4, 5, 6],\n",
       "         [0, 1, 2, ..., 4, 5, 6],\n",
       "         [0, 1, 2, ..., 4, 5, 6]]]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argsort()[-3:][::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3: Load the labels from models/squeezenet1.1/FP16/squeezenet1.1.labels into a numpy array. What is the first label inside the file?\n",
    "\n",
    "How to you read the labels from file and load it into a numpy array? <br />\n",
    "Hint: If you get stuck, you might want to check how it is done inside utils/opv.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:45:06.489148Z",
     "start_time": "2021-03-18T07:45:06.472155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tench, Tinca tinca' 'goldfish, Carassius auratus'\n",
      " 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias'\n",
      " 'tiger shark, Galeocerdo cuvieri' 'hammerhead, hammerhead shark'\n",
      " 'electric ray, crampfish, numbfish, torpedo' 'stingray' 'cock' 'hen'\n",
      " 'ostrich, Struthio camelus' 'brambling, Fringilla montifringilla'\n",
      " 'goldfinch, Carduelis carduelis'\n",
      " 'house finch, linnet, Carpodacus mexicanus' 'junco, snowbird'\n",
      " 'indigo bunting, indigo finch, indigo bird, Passerina cyanea'\n",
      " 'robin, American robin, Turdus migratorius' 'bulbul' 'jay' 'magpie'\n",
      " 'chickadee' 'water ouzel, dipper' 'kite'\n",
      " 'bald eagle, American eagle, Haliaeetus leucocephalus' 'vulture'\n",
      " 'great grey owl, great gray owl, Strix nebulosa'\n",
      " 'European fire salamander, Salamandra salamandra'\n",
      " 'common newt, Triturus vulgaris' 'eft'\n",
      " 'spotted salamander, Ambystoma maculatum'\n",
      " 'axolotl, mud puppy, Ambystoma mexicanum' 'bullfrog, Rana catesbeiana'\n",
      " 'tree frog, tree-frog'\n",
      " 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui'\n",
      " 'loggerhead, loggerhead turtle, Caretta caretta'\n",
      " 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea'\n",
      " 'mud turtle' 'terrapin' 'box turtle, box tortoise' 'banded gecko'\n",
      " 'common iguana, iguana, Iguana iguana'\n",
      " 'American chameleon, anole, Anolis carolinensis'\n",
      " 'whiptail, whiptail lizard' 'agama'\n",
      " 'frilled lizard, Chlamydosaurus kingi' 'alligator lizard'\n",
      " 'Gila monster, Heloderma suspectum' 'green lizard, Lacerta viridis'\n",
      " 'African chameleon, Chamaeleo chamaeleon'\n",
      " 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis'\n",
      " 'African crocodile, Nile crocodile, Crocodylus niloticus'\n",
      " 'American alligator, Alligator mississipiensis' 'triceratops'\n",
      " 'thunder snake, worm snake, Carphophis amoenus'\n",
      " 'ringneck snake, ring-necked snake, ring snake'\n",
      " 'hognose snake, puff adder, sand viper' 'green snake, grass snake'\n",
      " 'king snake, kingsnake' 'garter snake, grass snake' 'water snake'\n",
      " 'vine snake' 'night snake, Hypsiglena torquata'\n",
      " 'boa constrictor, Constrictor constrictor'\n",
      " 'rock python, rock snake, Python sebae' 'Indian cobra, Naja naja'\n",
      " 'green mamba' 'sea snake'\n",
      " 'horned viper, cerastes, sand viper, horned asp, Cerastes cornutus'\n",
      " 'diamondback, diamondback rattlesnake, Crotalus adamanteus'\n",
      " 'sidewinder, horned rattlesnake, Crotalus cerastes' 'trilobite'\n",
      " 'harvestman, daddy longlegs, Phalangium opilio' 'scorpion'\n",
      " 'black and gold garden spider, Argiope aurantia'\n",
      " 'barn spider, Araneus cavaticus' 'garden spider, Aranea diademata'\n",
      " 'black widow, Latrodectus mactans' 'tarantula'\n",
      " 'wolf spider, hunting spider' 'tick' 'centipede' 'black grouse'\n",
      " 'ptarmigan' 'ruffed grouse, partridge, Bonasa umbellus'\n",
      " 'prairie chicken, prairie grouse, prairie fowl' 'peacock' 'quail'\n",
      " 'partridge' 'African grey, African gray, Psittacus erithacus' 'macaw'\n",
      " 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita' 'lorikeet'\n",
      " 'coucal' 'bee eater' 'hornbill' 'hummingbird' 'jacamar' 'toucan' 'drake'\n",
      " 'red-breasted merganser, Mergus serrator' 'goose'\n",
      " 'black swan, Cygnus atratus' 'tusker' 'echidna, spiny anteater, anteater'\n",
      " 'platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus'\n",
      " 'wallaby, brush kangaroo'\n",
      " 'koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus'\n",
      " 'wombat' 'jellyfish' 'sea anemone, anemone' 'brain coral'\n",
      " 'flatworm, platyhelminth' 'nematode, nematode worm, roundworm' 'conch'\n",
      " 'snail' 'slug' 'sea slug, nudibranch'\n",
      " 'chiton, coat-of-mail shell, sea cradle, polyplacophore'\n",
      " 'chambered nautilus, pearly nautilus, nautilus'\n",
      " 'Dungeness crab, Cancer magister' 'rock crab, Cancer irroratus'\n",
      " 'fiddler crab'\n",
      " 'king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica'\n",
      " 'American lobster, Northern lobster, Maine lobster, Homarus americanus'\n",
      " 'spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish'\n",
      " 'crayfish, crawfish, crawdad, crawdaddy' 'hermit crab' 'isopod'\n",
      " 'white stork, Ciconia ciconia' 'black stork, Ciconia nigra' 'spoonbill'\n",
      " 'flamingo' 'little blue heron, Egretta caerulea'\n",
      " 'American egret, great white heron, Egretta albus' 'bittern' 'crane'\n",
      " 'limpkin, Aramus pictus' 'European gallinule, Porphyrio porphyrio'\n",
      " 'American coot, marsh hen, mud hen, water hen, Fulica americana'\n",
      " 'bustard' 'ruddy turnstone, Arenaria interpres'\n",
      " 'red-backed sandpiper, dunlin, Erolia alpina' 'redshank, Tringa totanus'\n",
      " 'dowitcher' 'oystercatcher, oyster catcher' 'pelican'\n",
      " 'king penguin, Aptenodytes patagonica' 'albatross, mollymawk'\n",
      " 'grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus'\n",
      " 'killer whale, killer, orca, grampus, sea wolf, Orcinus orca'\n",
      " 'dugong, Dugong dugon' 'sea lion' 'Chihuahua' 'Japanese spaniel'\n",
      " 'Maltese dog, Maltese terrier, Maltese' 'Pekinese, Pekingese, Peke'\n",
      " 'Shih-Tzu' 'Blenheim spaniel' 'papillon' 'toy terrier'\n",
      " 'Rhodesian ridgeback' 'Afghan hound, Afghan' 'basset, basset hound'\n",
      " 'beagle' 'bloodhound, sleuthhound' 'bluetick' 'black-and-tan coonhound'\n",
      " 'Walker hound, Walker foxhound' 'English foxhound' 'redbone'\n",
      " 'borzoi, Russian wolfhound' 'Irish wolfhound' 'Italian greyhound'\n",
      " 'whippet' 'Ibizan hound, Ibizan Podenco' 'Norwegian elkhound, elkhound'\n",
      " 'otterhound, otter hound' 'Saluki, gazelle hound'\n",
      " 'Scottish deerhound, deerhound' 'Weimaraner'\n",
      " 'Staffordshire bullterrier, Staffordshire bull terrier'\n",
      " 'American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier'\n",
      " 'Bedlington terrier' 'Border terrier' 'Kerry blue terrier'\n",
      " 'Irish terrier' 'Norfolk terrier' 'Norwich terrier' 'Yorkshire terrier'\n",
      " 'wire-haired fox terrier' 'Lakeland terrier' 'Sealyham terrier, Sealyham'\n",
      " 'Airedale, Airedale terrier' 'cairn, cairn terrier' 'Australian terrier'\n",
      " 'Dandie Dinmont, Dandie Dinmont terrier' 'Boston bull, Boston terrier'\n",
      " 'miniature schnauzer' 'giant schnauzer' 'standard schnauzer'\n",
      " 'Scotch terrier, Scottish terrier, Scottie'\n",
      " 'Tibetan terrier, chrysanthemum dog' 'silky terrier, Sydney silky'\n",
      " 'soft-coated wheaten terrier' 'West Highland white terrier'\n",
      " 'Lhasa, Lhasa apso' 'flat-coated retriever' 'curly-coated retriever'\n",
      " 'golden retriever' 'Labrador retriever' 'Chesapeake Bay retriever'\n",
      " 'German short-haired pointer' 'vizsla, Hungarian pointer'\n",
      " 'English setter' 'Irish setter, red setter' 'Gordon setter'\n",
      " 'Brittany spaniel' 'clumber, clumber spaniel'\n",
      " 'English springer, English springer spaniel' 'Welsh springer spaniel'\n",
      " 'cocker spaniel, English cocker spaniel, cocker' 'Sussex spaniel'\n",
      " 'Irish water spaniel' 'kuvasz' 'schipperke' 'groenendael' 'malinois'\n",
      " 'briard' 'kelpie' 'komondor' 'Old English sheepdog, bobtail'\n",
      " 'Shetland sheepdog, Shetland sheep dog, Shetland' 'collie'\n",
      " 'Border collie' 'Bouvier des Flandres, Bouviers des Flandres'\n",
      " 'Rottweiler'\n",
      " 'German shepherd, German shepherd dog, German police dog, alsatian'\n",
      " 'Doberman, Doberman pinscher' 'miniature pinscher'\n",
      " 'Greater Swiss Mountain dog' 'Bernese mountain dog' 'Appenzeller'\n",
      " 'EntleBucher' 'boxer' 'bull mastiff' 'Tibetan mastiff' 'French bulldog'\n",
      " 'Great Dane' 'Saint Bernard, St Bernard' 'Eskimo dog, husky'\n",
      " 'malamute, malemute, Alaskan malamute' 'Siberian husky'\n",
      " 'dalmatian, coach dog, carriage dog'\n",
      " 'affenpinscher, monkey pinscher, monkey dog' 'basenji' 'pug, pug-dog'\n",
      " 'Leonberg' 'Newfoundland, Newfoundland dog' 'Great Pyrenees'\n",
      " 'Samoyed, Samoyede' 'Pomeranian' 'chow, chow chow' 'keeshond'\n",
      " 'Brabancon griffon' 'Pembroke, Pembroke Welsh corgi'\n",
      " 'Cardigan, Cardigan Welsh corgi' 'toy poodle' 'miniature poodle'\n",
      " 'standard poodle' 'Mexican hairless'\n",
      " 'timber wolf, grey wolf, gray wolf, Canis lupus'\n",
      " 'white wolf, Arctic wolf, Canis lupus tundrarum'\n",
      " 'red wolf, maned wolf, Canis rufus, Canis niger'\n",
      " 'coyote, prairie wolf, brush wolf, Canis latrans'\n",
      " 'dingo, warrigal, warragal, Canis dingo' 'dhole, Cuon alpinus'\n",
      " 'African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus'\n",
      " 'hyena, hyaena' 'red fox, Vulpes vulpes' 'kit fox, Vulpes macrotis'\n",
      " 'Arctic fox, white fox, Alopex lagopus'\n",
      " 'grey fox, gray fox, Urocyon cinereoargenteus' 'tabby, tabby cat'\n",
      " 'tiger cat' 'Persian cat' 'Siamese cat, Siamese' 'Egyptian cat'\n",
      " 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'\n",
      " 'lynx, catamount' 'leopard, Panthera pardus'\n",
      " 'snow leopard, ounce, Panthera uncia'\n",
      " 'jaguar, panther, Panthera onca, Felis onca'\n",
      " 'lion, king of beasts, Panthera leo' 'tiger, Panthera tigris'\n",
      " 'cheetah, chetah, Acinonyx jubatus' 'brown bear, bruin, Ursus arctos'\n",
      " 'American black bear, black bear, Ursus americanus, Euarctos americanus'\n",
      " 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus'\n",
      " 'sloth bear, Melursus ursinus, Ursus ursinus' 'mongoose'\n",
      " 'meerkat, mierkat' 'tiger beetle'\n",
      " 'ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle'\n",
      " 'ground beetle, carabid beetle'\n",
      " 'long-horned beetle, longicorn, longicorn beetle'\n",
      " 'leaf beetle, chrysomelid' 'dung beetle' 'rhinoceros beetle' 'weevil'\n",
      " 'fly' 'bee' 'ant, emmet, pismire' 'grasshopper, hopper' 'cricket'\n",
      " 'walking stick, walkingstick, stick insect' 'cockroach, roach'\n",
      " 'mantis, mantid' 'cicada, cicala' 'leafhopper' 'lacewing, lacewing fly'\n",
      " \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\"\n",
      " 'damselfly' 'admiral' 'ringlet, ringlet butterfly'\n",
      " 'monarch, monarch butterfly, milkweed butterfly, Danaus plexippus'\n",
      " 'cabbage butterfly' 'sulphur butterfly, sulfur butterfly'\n",
      " 'lycaenid, lycaenid butterfly' 'starfish, sea star' 'sea urchin'\n",
      " 'sea cucumber, holothurian' 'wood rabbit, cottontail, cottontail rabbit'\n",
      " 'hare' 'Angora, Angora rabbit' 'hamster' 'porcupine, hedgehog'\n",
      " 'fox squirrel, eastern fox squirrel, Sciurus niger' 'marmot' 'beaver'\n",
      " 'guinea pig, Cavia cobaya' 'sorrel' 'zebra'\n",
      " 'hog, pig, grunter, squealer, Sus scrofa' 'wild boar, boar, Sus scrofa'\n",
      " 'warthog' 'hippopotamus, hippo, river horse, Hippopotamus amphibius' 'ox'\n",
      " 'water buffalo, water ox, Asiatic buffalo, Bubalus bubalis' 'bison'\n",
      " 'ram, tup'\n",
      " 'bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis'\n",
      " 'ibex, Capra ibex' 'hartebeest' 'impala, Aepyceros melampus' 'gazelle'\n",
      " 'Arabian camel, dromedary, Camelus dromedarius' 'llama' 'weasel' 'mink'\n",
      " 'polecat, fitch, foulmart, foumart, Mustela putorius'\n",
      " 'black-footed ferret, ferret, Mustela nigripes' 'otter'\n",
      " 'skunk, polecat, wood pussy' 'badger' 'armadillo'\n",
      " 'three-toed sloth, ai, Bradypus tridactylus'\n",
      " 'orangutan, orang, orangutang, Pongo pygmaeus' 'gorilla, Gorilla gorilla'\n",
      " 'chimpanzee, chimp, Pan troglodytes' 'gibbon, Hylobates lar'\n",
      " 'siamang, Hylobates syndactylus, Symphalangus syndactylus'\n",
      " 'guenon, guenon monkey' 'patas, hussar monkey, Erythrocebus patas'\n",
      " 'baboon' 'macaque' 'langur' 'colobus, colobus monkey'\n",
      " 'proboscis monkey, Nasalis larvatus' 'marmoset'\n",
      " 'capuchin, ringtail, Cebus capucinus' 'howler monkey, howler'\n",
      " 'titi, titi monkey' 'spider monkey, Ateles geoffroyi'\n",
      " 'squirrel monkey, Saimiri sciureus'\n",
      " 'Madagascar cat, ring-tailed lemur, Lemur catta'\n",
      " 'indri, indris, Indri indri, Indri brevicaudatus'\n",
      " 'Indian elephant, Elephas maximus' 'African elephant, Loxodonta africana'\n",
      " 'lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens'\n",
      " 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca'\n",
      " 'barracouta, snoek' 'eel'\n",
      " 'coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch'\n",
      " 'rock beauty, Holocanthus tricolor' 'anemone fish' 'sturgeon'\n",
      " 'gar, garfish, garpike, billfish, Lepisosteus osseus' 'lionfish'\n",
      " 'puffer, pufferfish, blowfish, globefish' 'abacus' 'abaya'\n",
      " \"academic gown, academic robe, judge's robe\"\n",
      " 'accordion, piano accordion, squeeze box' 'acoustic guitar'\n",
      " 'aircraft carrier, carrier, flattop, attack aircraft carrier' 'airliner'\n",
      " 'airship, dirigible' 'altar' 'ambulance' 'amphibian, amphibious vehicle'\n",
      " 'analog clock' 'apiary, bee house' 'apron'\n",
      " 'ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin'\n",
      " 'assault rifle, assault gun'\n",
      " 'backpack, back pack, knapsack, packsack, rucksack, haversack'\n",
      " 'bakery, bakeshop, bakehouse' 'balance beam, beam' 'balloon'\n",
      " 'ballpoint, ballpoint pen, ballpen, Biro' 'Band Aid' 'banjo'\n",
      " 'bannister, banister, balustrade, balusters, handrail' 'barbell'\n",
      " 'barber chair' 'barbershop' 'barn' 'barometer' 'barrel, cask'\n",
      " 'barrow, garden cart, lawn cart, wheelbarrow' 'baseball' 'basketball'\n",
      " 'bassinet' 'bassoon' 'bathing cap, swimming cap' 'bath towel'\n",
      " 'bathtub, bathing tub, bath, tub'\n",
      " 'beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon'\n",
      " 'beacon, lighthouse, beacon light, pharos' 'beaker'\n",
      " 'bearskin, busby, shako' 'beer bottle' 'beer glass' 'bell cote, bell cot'\n",
      " 'bib' 'bicycle-built-for-two, tandem bicycle, tandem' 'bikini, two-piece'\n",
      " 'binder, ring-binder' 'binoculars, field glasses, opera glasses'\n",
      " 'birdhouse' 'boathouse' 'bobsled, bobsleigh, bob'\n",
      " 'bolo tie, bolo, bola tie, bola' 'bonnet, poke bonnet' 'bookcase'\n",
      " 'bookshop, bookstore, bookstall' 'bottlecap' 'bow'\n",
      " 'bow tie, bow-tie, bowtie' 'brass, memorial tablet, plaque'\n",
      " 'brassiere, bra, bandeau'\n",
      " 'breakwater, groin, groyne, mole, bulwark, seawall, jetty'\n",
      " 'breastplate, aegis, egis' 'broom' 'bucket, pail' 'buckle'\n",
      " 'bulletproof vest' 'bullet train, bullet' 'butcher shop, meat market'\n",
      " 'cab, hack, taxi, taxicab' 'caldron, cauldron' 'candle, taper, wax light'\n",
      " 'cannon' 'canoe' 'can opener, tin opener' 'cardigan' 'car mirror'\n",
      " 'carousel, carrousel, merry-go-round, roundabout, whirligig'\n",
      " \"carpenter's kit, tool kit\" 'carton' 'car wheel'\n",
      " 'cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM'\n",
      " 'cassette' 'cassette player' 'castle' 'catamaran' 'CD player'\n",
      " 'cello, violoncello'\n",
      " 'cellular telephone, cellular phone, cellphone, cell, mobile phone'\n",
      " 'chain' 'chainlink fence'\n",
      " 'chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour'\n",
      " 'chain saw, chainsaw' 'chest' 'chiffonier, commode' 'chime, bell, gong'\n",
      " 'china cabinet, china closet' 'Christmas stocking'\n",
      " 'church, church building'\n",
      " 'cinema, movie theater, movie theatre, movie house, picture palace'\n",
      " 'cleaver, meat cleaver, chopper' 'cliff dwelling' 'cloak'\n",
      " 'clog, geta, patten, sabot' 'cocktail shaker' 'coffee mug' 'coffeepot'\n",
      " 'coil, spiral, volute, whorl, helix' 'combination lock'\n",
      " 'computer keyboard, keypad' 'confectionery, confectionary, candy store'\n",
      " 'container ship, containership, container vessel' 'convertible'\n",
      " 'corkscrew, bottle screw' 'cornet, horn, trumpet, trump' 'cowboy boot'\n",
      " 'cowboy hat, ten-gallon hat' 'cradle' 'crane' 'crash helmet' 'crate'\n",
      " 'crib, cot' 'Crock Pot' 'croquet ball' 'crutch' 'cuirass'\n",
      " 'dam, dike, dyke' 'desk' 'desktop computer' 'dial telephone, dial phone'\n",
      " 'diaper, nappy, napkin' 'digital clock' 'digital watch'\n",
      " 'dining table, board' 'dishrag, dishcloth'\n",
      " 'dishwasher, dish washer, dishwashing machine' 'disk brake, disc brake'\n",
      " 'dock, dockage, docking facility' 'dogsled, dog sled, dog sleigh' 'dome'\n",
      " 'doormat, welcome mat' 'drilling platform, offshore rig'\n",
      " 'drum, membranophone, tympan' 'drumstick' 'dumbbell' 'Dutch oven'\n",
      " 'electric fan, blower' 'electric guitar' 'electric locomotive'\n",
      " 'entertainment center' 'envelope' 'espresso maker' 'face powder'\n",
      " 'feather boa, boa' 'file, file cabinet, filing cabinet' 'fireboat'\n",
      " 'fire engine, fire truck' 'fire screen, fireguard' 'flagpole, flagstaff'\n",
      " 'flute, transverse flute' 'folding chair' 'football helmet' 'forklift'\n",
      " 'fountain' 'fountain pen' 'four-poster' 'freight car' 'French horn, horn'\n",
      " 'frying pan, frypan, skillet' 'fur coat' 'garbage truck, dustcart'\n",
      " 'gasmask, respirator, gas helmet'\n",
      " 'gas pump, gasoline pump, petrol pump, island dispenser' 'goblet'\n",
      " 'go-kart' 'golf ball' 'golfcart, golf cart' 'gondola' 'gong, tam-tam'\n",
      " 'gown' 'grand piano, grand' 'greenhouse, nursery, glasshouse'\n",
      " 'grille, radiator grille' 'grocery store, grocery, food market, market'\n",
      " 'guillotine' 'hair slide' 'hair spray' 'half track' 'hammer' 'hamper'\n",
      " 'hand blower, blow dryer, blow drier, hair dryer, hair drier'\n",
      " 'hand-held computer, hand-held microcomputer'\n",
      " 'handkerchief, hankie, hanky, hankey' 'hard disc, hard disk, fixed disk'\n",
      " 'harmonica, mouth organ, harp, mouth harp' 'harp' 'harvester, reaper'\n",
      " 'hatchet' 'holster' 'home theater, home theatre' 'honeycomb' 'hook, claw'\n",
      " 'hoopskirt, crinoline' 'horizontal bar, high bar'\n",
      " 'horse cart, horse-cart' 'hourglass' 'iPod' 'iron, smoothing iron'\n",
      " \"jack-o'-lantern\" 'jean, blue jean, denim' 'jeep, landrover'\n",
      " 'jersey, T-shirt, tee shirt' 'jigsaw puzzle'\n",
      " 'jinrikisha, ricksha, rickshaw' 'joystick' 'kimono' 'knee pad' 'knot'\n",
      " 'lab coat, laboratory coat' 'ladle' 'lampshade, lamp shade'\n",
      " 'laptop, laptop computer' 'lawn mower, mower' 'lens cap, lens cover'\n",
      " 'letter opener, paper knife, paperknife' 'library' 'lifeboat'\n",
      " 'lighter, light, igniter, ignitor' 'limousine, limo' 'liner, ocean liner'\n",
      " 'lipstick, lip rouge' 'Loafer' 'lotion'\n",
      " 'loudspeaker, speaker, speaker unit, loudspeaker system, speaker system'\n",
      " \"loupe, jeweler's loupe\" 'lumbermill, sawmill' 'magnetic compass'\n",
      " 'mailbag, postbag' 'mailbox, letter box' 'maillot' 'maillot, tank suit'\n",
      " 'manhole cover' 'maraca' 'marimba, xylophone' 'mask' 'matchstick'\n",
      " 'maypole' 'maze, labyrinth' 'measuring cup'\n",
      " 'medicine chest, medicine cabinet' 'megalith, megalithic structure'\n",
      " 'microphone, mike' 'microwave, microwave oven' 'military uniform'\n",
      " 'milk can' 'minibus' 'miniskirt, mini' 'minivan' 'missile' 'mitten'\n",
      " 'mixing bowl' 'mobile home, manufactured home' 'Model T' 'modem'\n",
      " 'monastery' 'monitor' 'moped' 'mortar' 'mortarboard' 'mosque'\n",
      " 'mosquito net' 'motor scooter, scooter'\n",
      " 'mountain bike, all-terrain bike, off-roader' 'mountain tent'\n",
      " 'mouse, computer mouse' 'mousetrap' 'moving van' 'muzzle' 'nail'\n",
      " 'neck brace' 'necklace' 'nipple' 'notebook, notebook computer' 'obelisk'\n",
      " 'oboe, hautboy, hautbois' 'ocarina, sweet potato'\n",
      " 'odometer, hodometer, mileometer, milometer' 'oil filter'\n",
      " 'organ, pipe organ' 'oscilloscope, scope, cathode-ray oscilloscope, CRO'\n",
      " 'overskirt' 'oxcart' 'oxygen mask' 'packet' 'paddle, boat paddle'\n",
      " 'paddlewheel, paddle wheel' 'padlock' 'paintbrush'\n",
      " \"pajama, pyjama, pj's, jammies\" 'palace' 'panpipe, pandean pipe, syrinx'\n",
      " 'paper towel' 'parachute, chute' 'parallel bars, bars' 'park bench'\n",
      " 'parking meter' 'passenger car, coach, carriage' 'patio, terrace'\n",
      " 'pay-phone, pay-station' 'pedestal, plinth, footstall'\n",
      " 'pencil box, pencil case' 'pencil sharpener' 'perfume, essence'\n",
      " 'Petri dish' 'photocopier' 'pick, plectrum, plectron' 'pickelhaube'\n",
      " 'picket fence, paling' 'pickup, pickup truck' 'pier'\n",
      " 'piggy bank, penny bank' 'pill bottle' 'pillow' 'ping-pong ball'\n",
      " 'pinwheel' 'pirate, pirate ship' 'pitcher, ewer'\n",
      " \"plane, carpenter's plane, woodworking plane\" 'planetarium' 'plastic bag'\n",
      " 'plate rack' 'plow, plough' \"plunger, plumber's helper\"\n",
      " 'Polaroid camera, Polaroid Land camera' 'pole'\n",
      " 'police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria'\n",
      " 'poncho' 'pool table, billiard table, snooker table'\n",
      " 'pop bottle, soda bottle' 'pot, flowerpot' \"potter's wheel\" 'power drill'\n",
      " 'prayer rug, prayer mat' 'printer' 'prison, prison house'\n",
      " 'projectile, missile' 'projector' 'puck, hockey puck'\n",
      " 'punching bag, punch bag, punching ball, punchball' 'purse'\n",
      " 'quill, quill pen' 'quilt, comforter, comfort, puff'\n",
      " 'racer, race car, racing car' 'racket, racquet' 'radiator'\n",
      " 'radio, wireless' 'radio telescope, radio reflector' 'rain barrel'\n",
      " 'recreational vehicle, RV, R.V.' 'reel' 'reflex camera'\n",
      " 'refrigerator, icebox' 'remote control, remote'\n",
      " 'restaurant, eating house, eating place, eatery'\n",
      " 'revolver, six-gun, six-shooter' 'rifle' 'rocking chair, rocker'\n",
      " 'rotisserie' 'rubber eraser, rubber, pencil eraser' 'rugby ball'\n",
      " 'rule, ruler' 'running shoe' 'safe' 'safety pin'\n",
      " 'saltshaker, salt shaker' 'sandal' 'sarong' 'sax, saxophone' 'scabbard'\n",
      " 'scale, weighing machine' 'school bus' 'schooner' 'scoreboard'\n",
      " 'screen, CRT screen' 'screw' 'screwdriver' 'seat belt, seatbelt'\n",
      " 'sewing machine' 'shield, buckler' 'shoe shop, shoe-shop, shoe store'\n",
      " 'shoji' 'shopping basket' 'shopping cart' 'shovel' 'shower cap'\n",
      " 'shower curtain' 'ski' 'ski mask' 'sleeping bag' 'slide rule, slipstick'\n",
      " 'sliding door' 'slot, one-armed bandit' 'snorkel' 'snowmobile'\n",
      " 'snowplow, snowplough' 'soap dispenser' 'soccer ball' 'sock'\n",
      " 'solar dish, solar collector, solar furnace' 'sombrero' 'soup bowl'\n",
      " 'space bar' 'space heater' 'space shuttle' 'spatula' 'speedboat'\n",
      " \"spider web, spider's web\" 'spindle' 'sports car, sport car'\n",
      " 'spotlight, spot' 'stage' 'steam locomotive' 'steel arch bridge'\n",
      " 'steel drum' 'stethoscope' 'stole' 'stone wall' 'stopwatch, stop watch'\n",
      " 'stove' 'strainer' 'streetcar, tram, tramcar, trolley, trolley car'\n",
      " 'stretcher' 'studio couch, day bed' 'stupa, tope'\n",
      " 'submarine, pigboat, sub, U-boat' 'suit, suit of clothes' 'sundial'\n",
      " 'sunglass' 'sunglasses, dark glasses, shades'\n",
      " 'sunscreen, sunblock, sun blocker' 'suspension bridge' 'swab, swob, mop'\n",
      " 'sweatshirt' 'swimming trunks, bathing trunks' 'swing'\n",
      " 'switch, electric switch, electrical switch' 'syringe' 'table lamp'\n",
      " 'tank, army tank, armored combat vehicle, armoured combat vehicle'\n",
      " 'tape player' 'teapot' 'teddy, teddy bear'\n",
      " 'television, television system' 'tennis ball' 'thatch, thatched roof'\n",
      " 'theater curtain, theatre curtain' 'thimble'\n",
      " 'thresher, thrasher, threshing machine' 'throne' 'tile roof' 'toaster'\n",
      " 'tobacco shop, tobacconist shop, tobacconist' 'toilet seat' 'torch'\n",
      " 'totem pole' 'tow truck, tow car, wrecker' 'toyshop' 'tractor'\n",
      " 'trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi'\n",
      " 'tray' 'trench coat' 'tricycle, trike, velocipede' 'trimaran' 'tripod'\n",
      " 'triumphal arch' 'trolleybus, trolley coach, trackless trolley'\n",
      " 'trombone' 'tub, vat' 'turnstile' 'typewriter keyboard' 'umbrella'\n",
      " 'unicycle, monocycle' 'upright, upright piano' 'vacuum, vacuum cleaner'\n",
      " 'vase' 'vault' 'velvet' 'vending machine' 'vestment' 'viaduct'\n",
      " 'violin, fiddle' 'volleyball' 'waffle iron' 'wall clock'\n",
      " 'wallet, billfold, notecase, pocketbook' 'wardrobe, closet, press'\n",
      " 'warplane, military plane'\n",
      " 'washbasin, handbasin, washbowl, lavabo, wash-hand basin'\n",
      " 'washer, automatic washer, washing machine' 'water bottle' 'water jug'\n",
      " 'water tower' 'whiskey jug' 'whistle' 'wig' 'window screen'\n",
      " 'window shade' 'Windsor tie' 'wine bottle' 'wing' 'wok' 'wooden spoon'\n",
      " 'wool, woolen, woollen'\n",
      " 'worm fence, snake fence, snake-rail fence, Virginia fence' 'wreck'\n",
      " 'yawl' 'yurt' 'web site, website, internet site, site' 'comic book'\n",
      " 'crossword puzzle, crossword' 'street sign'\n",
      " 'traffic light, traffic signal, stoplight'\n",
      " 'book jacket, dust cover, dust jacket, dust wrapper' 'menu' 'plate'\n",
      " 'guacamole' 'consomme' 'hot pot, hotpot' 'trifle' 'ice cream, icecream'\n",
      " 'ice lolly, lolly, lollipop, popsicle' 'French loaf' 'bagel, beigel'\n",
      " 'pretzel' 'cheeseburger' 'hotdog, hot dog, red hot' 'mashed potato'\n",
      " 'head cabbage' 'broccoli' 'cauliflower' 'zucchini, courgette'\n",
      " 'spaghetti squash' 'acorn squash' 'butternut squash' 'cucumber, cuke'\n",
      " 'artichoke, globe artichoke' 'bell pepper' 'cardoon' 'mushroom'\n",
      " 'Granny Smith' 'strawberry' 'orange' 'lemon' 'fig' 'pineapple, ananas'\n",
      " 'banana' 'jackfruit, jak, jack' 'custard apple' 'pomegranate' 'hay'\n",
      " 'carbonara' 'chocolate sauce, chocolate syrup' 'dough'\n",
      " 'meat loaf, meatloaf' 'pizza, pizza pie' 'potpie' 'burrito' 'red wine'\n",
      " 'espresso' 'cup' 'eggnog' 'alp' 'bubble' 'cliff, drop, drop-off'\n",
      " 'coral reef' 'geyser' 'lakeside, lakeshore'\n",
      " 'promontory, headland, head, foreland' 'sandbar, sand bar'\n",
      " 'seashore, coast, seacoast, sea-coast' 'valley, vale' 'volcano'\n",
      " 'ballplayer, baseball player' 'groom, bridegroom' 'scuba diver'\n",
      " 'rapeseed' 'daisy'\n",
      " \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\"\n",
      " 'corn' 'acorn' 'hip, rose hip, rosehip' 'buckeye, horse chestnut, conker'\n",
      " 'coral fungus' 'agaric' 'gyromitra' 'stinkhorn, carrion fungus'\n",
      " 'earthstar'\n",
      " 'hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa'\n",
      " 'bolete' 'ear, spike, capitulum'\n",
      " 'toilet tissue, toilet paper, bathroom tissue']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model_labels = \"./models/squeezenet1.1/FP16/squeezenet1.1.labels\"\n",
    "labels = np.loadtxt(model_labels,dtype=\"str\",delimiter=\"\\n\")\n",
    "\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 4: Use the classification model to classify images/pcb.png. Does it get classified as a printed circuit board (PCB)? Why do you think so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:45:11.008590Z",
     "start_time": "2021-03-18T07:45:10.273773Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] Loading network files:\n",
      "\tmodels/squeezenet1.1/FP32/squeezenet1.1.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classification_sample.py:76: DeprecationWarning: 'inputs' property of IENetwork class is deprecated. To access DataPtrs user need to use 'input_data' property of InputInfoPtr objects which can be accessed by 'input_info' property.\n",
      "  assert len(net.inputs.keys()) == 1, \"Sample supports only single input topologies\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tmodels/squeezenet1.1/FP32/squeezenet1.1.bin\n",
      "[ INFO ] Preparing input blobs\n",
      "[ WARNING ] Image images/pcb.png is resized from (480, 640) to (227, 227)\n",
      "[ INFO ] Batch size is 1\n",
      "[ INFO ] Loading model to the plugin\n",
      "[ INFO ] Starting inference (1 iterations)\n",
      "[ INFO ] Average running time of one iteration: 4.965066909790039 ms\n",
      "[ INFO ] Processing output blob\n",
      "[ INFO ] Top 10 results: \n",
      "Image images/pcb.png\n",
      "\n",
      "0.2059917 label site, website, internet site, site\n",
      "0.1430571 label sunblock, sun blocker\n",
      "0.1164520 label lotion\n",
      "0.0700398 label matchstick\n",
      "0.0449835 label carton\n",
      "0.0390331 label Aid\n",
      "0.0377465 label torch\n",
      "0.0373017 label packet\n",
      "0.0287694 label ring-binder\n",
      "0.0210595 label light, igniter, ignitor\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classification_sample.py -i images/pcb.png -m models/squeezenet1.1/FP32/squeezenet1.1.xml --labels models/squeezenet1.1/FP32/squeezenet1.1.labels\n",
    "\n",
    "\n",
    "# The model might have not been trained to classify this image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 5: Calculate how long it takes to make 1 prediction for the model in section 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:45:17.885181Z",
     "start_time": "2021-03-18T07:45:17.552148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32999730110168457 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def wastetime():\n",
    "    for i in range(0,10000000):\n",
    "        testing = 1\n",
    "        \n",
    "# Sample code for calculating time difference         \n",
    "a = time.time()\n",
    "wastetime()\n",
    "b = time.time()\n",
    "print(str(b-a) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:45:21.004509Z",
     "start_time": "2021-03-18T07:45:20.904511Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1492, 2520, 3)\n",
      "\t[INFO] Image resized from (1492, 2520) to (384, 672)\n",
      "(1, 1, 200, 7)\n",
      "0.03203582763671875 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "friends = cv2.imread(\"images/friends.jpeg\")\n",
    "print(friends.shape)\n",
    "a = time.time()\n",
    "predictions = mymodel2.Predict(friends)\n",
    "b = time.time()\n",
    "print(predictions.shape)\n",
    "print(str(b-a) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 6: Build an application that does real-time face detection via your webcam.\n",
    "\n",
    "Hint: Make use of what you learned in section 4, and what you already know about video capture via webcam from the earlier workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T07:45:34.694601Z",
     "start_time": "2021-03-18T07:45:28.340675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n",
      "\t[INFO] Image resized from (480, 640) to (384, 672)\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0) #create a VideoCapture object with the 'first' camera (your webcam)\n",
    "\n",
    "def DrawBoundingBoxes(predictions, image, conf=0.5):\n",
    "    canvas = image.copy()                             # copy instead of modifying the original image\n",
    "    predictions = predictions[0][0]\n",
    "    confidence = predictions[:,2]\n",
    "    topresults = predictions[(confidence>conf)]\n",
    "    canshp = canvas.shape[:2]\n",
    "    (h,w) = canvas.shape[:2]\n",
    "    for detection in topresults:\n",
    "        box = detection[3:7] * np.array([w, h, w, h])\n",
    "        (xmin, ymin, xmax, ymax) = box.astype(\"int\")\n",
    "\n",
    "        cv2.rectangle(canvas, (xmin, ymin), (xmax, ymax), (0, 0, 255), 4)\n",
    "        cv2.putText(canvas, str(round(detection[2]*100,1))+\"%\", (xmin, ymin),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    cv2.putText(canvas, str(len(topresults))+\" face(s) detected\", (50,50),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0,0), 2)\n",
    "    return canvas, canshp\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()             # Capture frame by frame      \n",
    "    predictions = mymodel2.Predict(frame)\n",
    "    canvas, canshp = DrawBoundingBoxes(predictions,frame)\n",
    "    cv2.imshow('Press Spacebar to Exit', canvas)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):  # Stop if spacebar is detected\n",
    "        break\n",
    "\n",
    "camera.release()                           # Cleanup after spacebar is detected.\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 7: Do the real-time face detections look a little laggy on your screen? Can you think of 1 or more ways to make the detections faster?\n",
    "\n",
    "Hint: Remember that the bigger the image, the more the processing required. Also, not all models are made alike. Think of different possibilities and try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can get youths to try resizing the video, use other models they have learnt, use more NCS2 sticks, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 8: Can I use 2 NCS devices at the same time?\n",
    "\n",
    "If you borrow one more NCS device from your friend, you can try running both the face detection and the classification model at the same time. Set the ncs flag to 1 for the first, and set the ncs flag to 2 for the second model. You can also set the debug flag to True to see the output.\n",
    "\n",
    "For example, <br />\n",
    "mymodel = OpvModel(\"face-detection-retail-0004\", device=\"MYRIAD\", fp=\"FP16\", ncs=1, debug = True) <br />\n",
    "mymodel2 = OpvModel(\"squeezenet1.1\", device=\"MYRIAD\", fp=\"FP16\", ncs=2, debug = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yes, you can do that. Get your youths to try this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 9: Touch your NCS2. Does it feel hot?\n",
    "\n",
    "To release the NCS2, you will need to release that memory. Automatic [garbage collection](https://docs.python.org/3/library/gc.html) does not happen for the OpvModel yet because mymodel is still defined and the Jupyter Notebook session has not ended. And OpvModel holds a reference to the NCS2 which holds the model that you loaded earlier.\n",
    "\n",
    "To release that reference, you can do:\n",
    "1. mymodel.ClearMachine(), or\n",
    "2. halt and close this notebook, or \n",
    "3. plug out the NCS2 when no longer in use.\n",
    "\n",
    "For safety, it might be a good pratice to plug out the NCS2 from the USB port when not in use to prevent overheating.\n",
    "\n",
    "Also keep a lookout for when the new Python API for the NCS2 might be released."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.ClearMachine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 10: Take a look at the Intel Documentation of Pre-Trained Models, how many types of models can you find?\n",
    "You can find the documentation at %OPENVINO_INSTALL_DIR%/Intel/computer_vision_sdk/deployment_tools/\n",
    "intel_models/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are you having fun?\n",
    "\n",
    "We sure hope you are! Be sure to remember to think of ways that you can put what you learn to good use. Remember, with great power comes great responsibility! Use your knowledge to design and develop solutions to help people and society around you! \n",
    "\n",
    "Up to this point, we have only tested out 3 pre-trained models. Be sure to explore the many other pre-trained models that Intel has provided together with the OpenVINO installation!\n",
    "\n",
    "Welcome to the beginning of your exciting journey of learning ahead!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
